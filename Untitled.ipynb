{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.main import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datamanager import DataManager\n",
    "from src.data.window import WindowSequence, KerasSequence\n",
    "from src.data.dataset import MotionSense, Activity\n",
    "from src.visual.plotter import Plotter, VecData\n",
    "from src.network.gan import Gan, SimpleGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import toml\n",
    "datasets = toml.load(\"config.toml\")[\"dataset\"]\n",
    "WISDM_PATH = Path(datasets[\"wisdm\"])\n",
    "MOTION_SENSE_PATH = Path(datasets[\"motion-sense\"])\n",
    "\n",
    "\n",
    "dataset = MotionSense(MOTION_SENSE_PATH)\n",
    "datamanager = DataManager(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = datamanager.create_windows(set(Activity), 100, shuffle=True, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows.to_keras_sequence(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = SimpleGan(windows.get_shape(only_numeric=True), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orcan/.local/share/virtualenvs/user-activity-generator-2M2ZtGjA/lib/python3.8/site-packages/keras/engine/training.py:296: UserWarning:\n",
      "\n",
      "Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0:   0 [D loss: 0.670, acc:  38] [G loss: 0.555]\n",
      " 0:   1 [D loss: 0.468, acc:  58] [G loss: 0.548]\n",
      " 0:   2 [D loss: 0.451, acc:  56] [G loss: 0.473]\n",
      " 0:   3 [D loss: 0.457, acc:  50] [G loss: 0.491]\n",
      " 0:   4 [D loss: 0.516, acc:  48] [G loss: 0.452]\n",
      " 0:   5 [D loss: 0.528, acc:  48] [G loss: 0.454]\n",
      " 0:   6 [D loss: 0.565, acc:  50] [G loss: 0.459]\n",
      " 0:   7 [D loss: 0.608, acc:  47] [G loss: 0.492]\n",
      " 0:   8 [D loss: 0.632, acc:  52] [G loss: 0.438]\n",
      " 0:   9 [D loss: 0.717, acc:  48] [G loss: 0.404]\n",
      " 0:  10 [D loss: 0.731, acc:  50] [G loss: 0.407]\n",
      " 0:  11 [D loss: 0.751, acc:  50] [G loss: 0.351]\n",
      " 0:  12 [D loss: 0.769, acc:  50] [G loss: 0.388]\n",
      " 0:  13 [D loss: 0.802, acc:  50] [G loss: 0.352]\n",
      " 0:  14 [D loss: 0.855, acc:  48] [G loss: 0.374]\n",
      " 0:  15 [D loss: 0.773, acc:  50] [G loss: 0.347]\n",
      " 0:  16 [D loss: 0.959, acc:  50] [G loss: 0.316]\n",
      " 0:  17 [D loss: 0.898, acc:  50] [G loss: 0.334]\n",
      " 0:  18 [D loss: 0.926, acc:  50] [G loss: 0.330]\n",
      " 0:  19 [D loss: 1.020, acc:  50] [G loss: 0.286]\n",
      " 0:  20 [D loss: 0.994, acc:  50] [G loss: 0.265]\n",
      " 0:  21 [D loss: 1.063, acc:  50] [G loss: 0.298]\n",
      " 0:  22 [D loss: 1.065, acc:  50] [G loss: 0.244]\n",
      " 0:  23 [D loss: 1.107, acc:  50] [G loss: 0.248]\n",
      " 0:  24 [D loss: 1.083, acc:  50] [G loss: 0.254]\n",
      " 0:  25 [D loss: 1.179, acc:  50] [G loss: 0.312]\n",
      " 0:  26 [D loss: 1.314, acc:  48] [G loss: 0.226]\n",
      " 0:  27 [D loss: 1.267, acc:  50] [G loss: 0.237]\n",
      " 0:  28 [D loss: 1.233, acc:  50] [G loss: 0.226]\n",
      " 0:  29 [D loss: 1.230, acc:  48] [G loss: 0.222]\n",
      " 0:  30 [D loss: 1.282, acc:  50] [G loss: 0.234]\n",
      " 0:  31 [D loss: 1.364, acc:  48] [G loss: 0.216]\n",
      " 0:  32 [D loss: 1.341, acc:  50] [G loss: 0.211]\n",
      " 0:  33 [D loss: 1.383, acc:  50] [G loss: 0.212]\n",
      " 0:  34 [D loss: 1.367, acc:  50] [G loss: 0.204]\n",
      " 0:  35 [D loss: 1.454, acc:  50] [G loss: 0.197]\n",
      " 0:  36 [D loss: 1.437, acc:  50] [G loss: 0.165]\n",
      " 0:  37 [D loss: 1.452, acc:  50] [G loss: 0.181]\n",
      " 0:  38 [D loss: 1.519, acc:  50] [G loss: 0.179]\n",
      " 0:  39 [D loss: 1.569, acc:  48] [G loss: 0.171]\n",
      " 0:  40 [D loss: 1.507, acc:  48] [G loss: 0.154]\n",
      " 0:  41 [D loss: 1.597, acc:  50] [G loss: 0.166]\n",
      " 0:  42 [D loss: 1.716, acc:  48] [G loss: 0.133]\n",
      " 0:  43 [D loss: 1.625, acc:  50] [G loss: 0.142]\n",
      " 0:  44 [D loss: 1.642, acc:  50] [G loss: 0.160]\n",
      " 0:  45 [D loss: 1.754, acc:  50] [G loss: 0.119]\n",
      " 0:  46 [D loss: 1.657, acc:  50] [G loss: 0.150]\n",
      " 0:  47 [D loss: 1.714, acc:  50] [G loss: 0.141]\n",
      " 0:  48 [D loss: 1.778, acc:  50] [G loss: 0.133]\n",
      " 0:  49 [D loss: 1.735, acc:  50] [G loss: 0.142]\n",
      " 0:  50 [D loss: 1.837, acc:  48] [G loss: 0.126]\n",
      " 0:  51 [D loss: 1.845, acc:  50] [G loss: 0.132]\n",
      " 0:  52 [D loss: 1.862, acc:  50] [G loss: 0.125]\n",
      " 0:  53 [D loss: 1.885, acc:  50] [G loss: 0.115]\n",
      " 0:  54 [D loss: 1.943, acc:  50] [G loss: 0.106]\n",
      " 0:  55 [D loss: 1.917, acc:  50] [G loss: 0.118]\n",
      " 0:  56 [D loss: 1.922, acc:  50] [G loss: 0.106]\n",
      " 0:  57 [D loss: 1.977, acc:  50] [G loss: 0.102]\n",
      " 0:  58 [D loss: 1.901, acc:  50] [G loss: 0.124]\n",
      " 0:  59 [D loss: 2.013, acc:  50] [G loss: 0.083]\n",
      " 0:  60 [D loss: 1.995, acc:  50] [G loss: 0.111]\n",
      " 0:  61 [D loss: 2.017, acc:  50] [G loss: 0.097]\n",
      " 0:  62 [D loss: 2.161, acc:  50] [G loss: 0.073]\n",
      " 0:  63 [D loss: 1.937, acc:  50] [G loss: 0.099]\n",
      " 0:  64 [D loss: 2.119, acc:  50] [G loss: 0.084]\n",
      " 0:  65 [D loss: 2.101, acc:  50] [G loss: 0.080]\n",
      " 0:  66 [D loss: 2.235, acc:  50] [G loss: 0.073]\n",
      " 0:  67 [D loss: 2.171, acc:  50] [G loss: 0.089]\n",
      " 0:  68 [D loss: 2.033, acc:  50] [G loss: 0.090]\n",
      " 0:  69 [D loss: 2.113, acc:  50] [G loss: 0.086]\n",
      " 0:  70 [D loss: 2.067, acc:  50] [G loss: 0.102]\n",
      " 0:  71 [D loss: 2.094, acc:  50] [G loss: 0.086]\n",
      " 0:  72 [D loss: 2.193, acc:  48] [G loss: 0.081]\n",
      " 0:  73 [D loss: 2.323, acc:  50] [G loss: 0.075]\n",
      " 0:  74 [D loss: 2.191, acc:  50] [G loss: 0.067]\n",
      " 0:  75 [D loss: 2.201, acc:  50] [G loss: 0.072]\n",
      " 0:  76 [D loss: 2.381, acc:  50] [G loss: 0.072]\n",
      " 0:  77 [D loss: 2.204, acc:  50] [G loss: 0.070]\n",
      " 0:  78 [D loss: 2.241, acc:  50] [G loss: 0.077]\n",
      " 0:  79 [D loss: 2.305, acc:  50] [G loss: 0.075]\n",
      " 0:  80 [D loss: 2.314, acc:  50] [G loss: 0.076]\n",
      " 0:  81 [D loss: 2.360, acc:  50] [G loss: 0.068]\n",
      " 0:  82 [D loss: 2.470, acc:  50] [G loss: 0.056]\n",
      " 0:  83 [D loss: 2.279, acc:  50] [G loss: 0.068]\n",
      " 0:  84 [D loss: 2.391, acc:  50] [G loss: 0.069]\n",
      " 0:  85 [D loss: 2.250, acc:  50] [G loss: 0.072]\n",
      " 0:  86 [D loss: 2.448, acc:  50] [G loss: 0.062]\n",
      " 0:  87 [D loss: 2.531, acc:  50] [G loss: 0.054]\n",
      " 0:  88 [D loss: 2.399, acc:  50] [G loss: 0.066]\n",
      " 0:  89 [D loss: 2.364, acc:  50] [G loss: 0.063]\n",
      " 0:  90 [D loss: 2.455, acc:  50] [G loss: 0.062]\n",
      " 0:  91 [D loss: 2.662, acc:  48] [G loss: 0.045]\n",
      " 0:  92 [D loss: 2.546, acc:  50] [G loss: 0.053]\n",
      " 0:  93 [D loss: 2.402, acc:  50] [G loss: 0.061]\n",
      " 0:  94 [D loss: 2.546, acc:  50] [G loss: 0.051]\n",
      " 0:  95 [D loss: 2.641, acc:  50] [G loss: 0.044]\n",
      " 0:  96 [D loss: 2.486, acc:  50] [G loss: 0.053]\n",
      " 0:  97 [D loss: 2.529, acc:  50] [G loss: 0.050]\n",
      " 0:  98 [D loss: 2.605, acc:  50] [G loss: 0.049]\n",
      " 0:  99 [D loss: 2.682, acc:  50] [G loss: 0.043]\n",
      " 0: 100 [D loss: 2.396, acc:  50] [G loss: 0.075]\n",
      " 0: 101 [D loss: 2.601, acc:  50] [G loss: 0.047]\n",
      " 0: 102 [D loss: 2.507, acc:  50] [G loss: 0.062]\n",
      " 0: 103 [D loss: 2.745, acc:  48] [G loss: 0.044]\n",
      " 0: 104 [D loss: 2.584, acc:  50] [G loss: 0.053]\n",
      " 0: 105 [D loss: 2.575, acc:  50] [G loss: 0.054]\n",
      " 0: 106 [D loss: 2.653, acc:  50] [G loss: 0.043]\n",
      " 0: 107 [D loss: 2.752, acc:  50] [G loss: 0.041]\n",
      " 0: 108 [D loss: 2.579, acc:  48] [G loss: 0.060]\n",
      " 0: 109 [D loss: 2.612, acc:  48] [G loss: 0.042]\n",
      " 0: 110 [D loss: 2.664, acc:  50] [G loss: 0.043]\n",
      " 0: 111 [D loss: 2.498, acc:  50] [G loss: 0.058]\n",
      " 0: 112 [D loss: 2.669, acc:  50] [G loss: 0.047]\n",
      " 0: 113 [D loss: 2.730, acc:  48] [G loss: 0.037]\n",
      " 0: 114 [D loss: 2.675, acc:  50] [G loss: 0.038]\n",
      " 0: 115 [D loss: 2.713, acc:  48] [G loss: 0.048]\n",
      " 0: 116 [D loss: 2.743, acc:  50] [G loss: 0.046]\n",
      " 0: 117 [D loss: 2.675, acc:  48] [G loss: 0.044]\n",
      " 0: 118 [D loss: 2.831, acc:  48] [G loss: 0.040]\n",
      " 0: 119 [D loss: 2.653, acc:  48] [G loss: 0.053]\n",
      " 0: 120 [D loss: 2.718, acc:  50] [G loss: 0.046]\n",
      " 0: 121 [D loss: 3.007, acc:  47] [G loss: 0.036]\n",
      " 0: 122 [D loss: 2.790, acc:  45] [G loss: 0.056]\n",
      " 0: 123 [D loss: 2.776, acc:  48] [G loss: 0.052]\n",
      " 0: 124 [D loss: 2.916, acc:  50] [G loss: 0.032]\n",
      " 0: 125 [D loss: 2.602, acc:  50] [G loss: 0.054]\n",
      " 0: 126 [D loss: 2.745, acc:  50] [G loss: 0.052]\n",
      " 0: 127 [D loss: 2.739, acc:  50] [G loss: 0.045]\n",
      " 0: 128 [D loss: 2.902, acc:  48] [G loss: 0.044]\n",
      " 0: 129 [D loss: 2.714, acc:  47] [G loss: 0.052]\n",
      " 0: 130 [D loss: 2.928, acc:  50] [G loss: 0.033]\n",
      " 0: 131 [D loss: 2.944, acc:  50] [G loss: 0.032]\n",
      " 0: 132 [D loss: 2.552, acc:  50] [G loss: 0.054]\n",
      " 0: 133 [D loss: 2.824, acc:  50] [G loss: 0.039]\n",
      " 0: 134 [D loss: 2.869, acc:  48] [G loss: 0.038]\n",
      " 0: 135 [D loss: 2.921, acc:  50] [G loss: 0.023]\n",
      " 0: 136 [D loss: 2.673, acc:  50] [G loss: 0.048]\n",
      " 0: 137 [D loss: 2.791, acc:  50] [G loss: 0.045]\n",
      " 0: 138 [D loss: 2.816, acc:  47] [G loss: 0.043]\n",
      " 0: 139 [D loss: 2.826, acc:  50] [G loss: 0.040]\n",
      " 0: 140 [D loss: 2.849, acc:  48] [G loss: 0.033]\n",
      " 0: 141 [D loss: 2.868, acc:  50] [G loss: 0.028]\n",
      " 0: 142 [D loss: 2.675, acc:  50] [G loss: 0.042]\n",
      " 0: 143 [D loss: 2.923, acc:  48] [G loss: 0.036]\n",
      " 0: 144 [D loss: 2.951, acc:  47] [G loss: 0.038]\n",
      " 0: 145 [D loss: 2.756, acc:  50] [G loss: 0.040]\n",
      " 0: 146 [D loss: 2.867, acc:  47] [G loss: 0.033]\n",
      " 0: 147 [D loss: 2.921, acc:  50] [G loss: 0.032]\n",
      " 0: 148 [D loss: 2.860, acc:  50] [G loss: 0.039]\n",
      " 0: 149 [D loss: 2.785, acc:  50] [G loss: 0.043]\n",
      " 0: 150 [D loss: 2.918, acc:  47] [G loss: 0.030]\n",
      " 0: 151 [D loss: 2.871, acc:  48] [G loss: 0.039]\n",
      " 0: 152 [D loss: 2.824, acc:  48] [G loss: 0.044]\n",
      " 0: 153 [D loss: 2.730, acc:  50] [G loss: 0.037]\n",
      " 0: 154 [D loss: 2.737, acc:  50] [G loss: 0.040]\n",
      " 0: 155 [D loss: 2.774, acc:  50] [G loss: 0.034]\n",
      " 0: 156 [D loss: 2.704, acc:  50] [G loss: 0.050]\n",
      " 0: 157 [D loss: 2.940, acc:  50] [G loss: 0.034]\n",
      " 0: 158 [D loss: 2.953, acc:  48] [G loss: 0.032]\n",
      " 0: 159 [D loss: 2.820, acc:  50] [G loss: 0.043]\n",
      " 0: 160 [D loss: 2.769, acc:  48] [G loss: 0.038]\n",
      " 0: 161 [D loss: 2.915, acc:  50] [G loss: 0.029]\n",
      " 0: 162 [D loss: 2.937, acc:  48] [G loss: 0.031]\n",
      " 0: 163 [D loss: 2.888, acc:  48] [G loss: 0.039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: 164 [D loss: 3.029, acc:  48] [G loss: 0.036]\n",
      " 0: 165 [D loss: 2.887, acc:  48] [G loss: 0.034]\n",
      " 0: 166 [D loss: 2.808, acc:  48] [G loss: 0.038]\n",
      " 0: 167 [D loss: 2.886, acc:  48] [G loss: 0.037]\n",
      " 0: 168 [D loss: 2.890, acc:  50] [G loss: 0.034]\n",
      " 0: 169 [D loss: 2.788, acc:  50] [G loss: 0.033]\n",
      " 0: 170 [D loss: 2.840, acc:  50] [G loss: 0.035]\n",
      " 0: 171 [D loss: 2.823, acc:  47] [G loss: 0.042]\n",
      " 0: 172 [D loss: 2.870, acc:  48] [G loss: 0.034]\n",
      " 0: 173 [D loss: 2.869, acc:  50] [G loss: 0.049]\n",
      " 0: 174 [D loss: 2.865, acc:  47] [G loss: 0.046]\n",
      " 0: 175 [D loss: 2.923, acc:  45] [G loss: 0.036]\n",
      " 0: 176 [D loss: 2.845, acc:  48] [G loss: 0.035]\n",
      " 0: 177 [D loss: 2.834, acc:  50] [G loss: 0.035]\n",
      " 0: 178 [D loss: 2.883, acc:  48] [G loss: 0.031]\n",
      " 0: 179 [D loss: 2.876, acc:  50] [G loss: 0.031]\n",
      " 0: 180 [D loss: 2.978, acc:  48] [G loss: 0.031]\n",
      " 0: 181 [D loss: 2.959, acc:  48] [G loss: 0.036]\n",
      " 0: 182 [D loss: 2.826, acc:  50] [G loss: 0.036]\n",
      " 0: 183 [D loss: 2.909, acc:  47] [G loss: 0.032]\n",
      " 0: 184 [D loss: 2.905, acc:  50] [G loss: 0.025]\n",
      " 0: 185 [D loss: 2.760, acc:  50] [G loss: 0.038]\n",
      " 0: 186 [D loss: 2.863, acc:  50] [G loss: 0.030]\n",
      " 0: 187 [D loss: 2.940, acc:  45] [G loss: 0.025]\n",
      " 0: 188 [D loss: 2.914, acc:  45] [G loss: 0.035]\n",
      " 0: 189 [D loss: 2.974, acc:  50] [G loss: 0.028]\n",
      " 0: 190 [D loss: 2.937, acc:  48] [G loss: 0.031]\n",
      " 0: 191 [D loss: 2.678, acc:  50] [G loss: 0.043]\n",
      " 0: 192 [D loss: 2.904, acc:  47] [G loss: 0.027]\n",
      " 0: 193 [D loss: 2.846, acc:  50] [G loss: 0.034]\n",
      " 0: 194 [D loss: 2.695, acc:  48] [G loss: 0.051]\n",
      " 0: 195 [D loss: 2.807, acc:  48] [G loss: 0.041]\n",
      " 0: 196 [D loss: 2.838, acc:  47] [G loss: 0.048]\n",
      " 0: 197 [D loss: 2.744, acc:  48] [G loss: 0.054]\n",
      " 0: 198 [D loss: 2.819, acc:  48] [G loss: 0.047]\n",
      " 0: 199 [D loss: 2.773, acc:  50] [G loss: 0.034]\n",
      " 0: 200 [D loss: 2.800, acc:  48] [G loss: 0.032]\n",
      " 0: 201 [D loss: 2.930, acc:  47] [G loss: 0.038]\n",
      " 0: 202 [D loss: 2.961, acc:  47] [G loss: 0.029]\n",
      " 0: 203 [D loss: 2.823, acc:  48] [G loss: 0.050]\n",
      " 0: 204 [D loss: 2.763, acc:  50] [G loss: 0.037]\n",
      " 0: 205 [D loss: 2.889, acc:  47] [G loss: 0.036]\n",
      " 0: 206 [D loss: 2.804, acc:  48] [G loss: 0.039]\n",
      " 0: 207 [D loss: 2.840, acc:  50] [G loss: 0.035]\n",
      " 0: 208 [D loss: 2.699, acc:  45] [G loss: 0.043]\n",
      " 0: 209 [D loss: 2.862, acc:  50] [G loss: 0.033]\n",
      " 0: 210 [D loss: 2.738, acc:  48] [G loss: 0.038]\n",
      " 0: 211 [D loss: 2.760, acc:  50] [G loss: 0.031]\n",
      " 0: 212 [D loss: 2.744, acc:  50] [G loss: 0.029]\n",
      " 0: 213 [D loss: 2.851, acc:  48] [G loss: 0.026]\n",
      " 0: 214 [D loss: 2.829, acc:  48] [G loss: 0.033]\n",
      " 0: 215 [D loss: 2.700, acc:  45] [G loss: 0.040]\n",
      " 0: 216 [D loss: 2.906, acc:  47] [G loss: 0.041]\n",
      " 0: 217 [D loss: 2.749, acc:  50] [G loss: 0.025]\n",
      " 0: 218 [D loss: 2.887, acc:  47] [G loss: 0.027]\n",
      " 0: 219 [D loss: 2.696, acc:  50] [G loss: 0.038]\n",
      " 0: 220 [D loss: 2.734, acc:  48] [G loss: 0.034]\n",
      " 0: 221 [D loss: 2.726, acc:  48] [G loss: 0.028]\n",
      " 0: 222 [D loss: 2.728, acc:  47] [G loss: 0.033]\n",
      " 0: 223 [D loss: 2.724, acc:  47] [G loss: 0.033]\n",
      " 0: 224 [D loss: 2.671, acc:  48] [G loss: 0.041]\n",
      " 0: 225 [D loss: 2.607, acc:  50] [G loss: 0.040]\n",
      " 0: 226 [D loss: 2.666, acc:  50] [G loss: 0.040]\n",
      " 0: 227 [D loss: 2.797, acc:  47] [G loss: 0.035]\n",
      " 0: 228 [D loss: 2.704, acc:  50] [G loss: 0.034]\n",
      " 0: 229 [D loss: 2.826, acc:  47] [G loss: 0.033]\n",
      " 0: 230 [D loss: 2.660, acc:  45] [G loss: 0.052]\n",
      " 0: 231 [D loss: 2.653, acc:  50] [G loss: 0.039]\n",
      " 0: 232 [D loss: 2.705, acc:  48] [G loss: 0.042]\n",
      " 0: 233 [D loss: 2.554, acc:  48] [G loss: 0.049]\n",
      " 0: 234 [D loss: 2.663, acc:  45] [G loss: 0.046]\n",
      " 0: 235 [D loss: 2.675, acc:  45] [G loss: 0.039]\n",
      " 0: 236 [D loss: 2.752, acc:  45] [G loss: 0.037]\n",
      " 0: 237 [D loss: 2.788, acc:  45] [G loss: 0.038]\n",
      " 0: 238 [D loss: 2.658, acc:  50] [G loss: 0.033]\n",
      " 0: 239 [D loss: 2.586, acc:  48] [G loss: 0.036]\n",
      " 0: 240 [D loss: 2.643, acc:  48] [G loss: 0.045]\n",
      " 0: 241 [D loss: 2.569, acc:  50] [G loss: 0.031]\n",
      " 0: 242 [D loss: 2.628, acc:  48] [G loss: 0.045]\n",
      " 0: 243 [D loss: 2.697, acc:  42] [G loss: 0.043]\n",
      " 0: 244 [D loss: 2.763, acc:  47] [G loss: 0.036]\n",
      " 0: 245 [D loss: 2.536, acc:  48] [G loss: 0.052]\n",
      " 0: 246 [D loss: 2.680, acc:  47] [G loss: 0.034]\n",
      " 0: 247 [D loss: 2.576, acc:  48] [G loss: 0.041]\n",
      " 0: 248 [D loss: 2.580, acc:  48] [G loss: 0.045]\n",
      " 0: 249 [D loss: 2.699, acc:  45] [G loss: 0.039]\n",
      " 0: 250 [D loss: 2.585, acc:  47] [G loss: 0.056]\n",
      " 0: 251 [D loss: 2.657, acc:  45] [G loss: 0.051]\n",
      " 0: 252 [D loss: 2.524, acc:  50] [G loss: 0.039]\n",
      " 0: 253 [D loss: 2.471, acc:  50] [G loss: 0.046]\n",
      " 0: 254 [D loss: 2.519, acc:  47] [G loss: 0.043]\n",
      " 0: 255 [D loss: 2.589, acc:  45] [G loss: 0.044]\n",
      " 0: 256 [D loss: 2.513, acc:  47] [G loss: 0.039]\n",
      " 0: 257 [D loss: 2.443, acc:  48] [G loss: 0.048]\n",
      " 0: 258 [D loss: 2.597, acc:  47] [G loss: 0.045]\n",
      " 0: 259 [D loss: 2.647, acc:  47] [G loss: 0.039]\n",
      " 0: 260 [D loss: 2.458, acc:  50] [G loss: 0.049]\n",
      " 0: 261 [D loss: 2.500, acc:  47] [G loss: 0.041]\n",
      " 0: 262 [D loss: 2.458, acc:  44] [G loss: 0.046]\n",
      " 0: 263 [D loss: 2.436, acc:  48] [G loss: 0.053]\n",
      " 0: 264 [D loss: 2.408, acc:  48] [G loss: 0.049]\n",
      " 0: 265 [D loss: 2.545, acc:  44] [G loss: 0.045]\n",
      " 0: 266 [D loss: 2.539, acc:  44] [G loss: 0.040]\n",
      " 0: 267 [D loss: 2.411, acc:  50] [G loss: 0.048]\n",
      " 0: 268 [D loss: 2.465, acc:  48] [G loss: 0.053]\n",
      " 0: 269 [D loss: 2.572, acc:  45] [G loss: 0.067]\n",
      " 0: 270 [D loss: 2.417, acc:  47] [G loss: 0.053]\n",
      " 0: 271 [D loss: 2.398, acc:  45] [G loss: 0.058]\n",
      " 0: 272 [D loss: 2.377, acc:  48] [G loss: 0.047]\n",
      " 0: 273 [D loss: 2.480, acc:  45] [G loss: 0.053]\n",
      " 0: 274 [D loss: 2.328, acc:  48] [G loss: 0.062]\n",
      " 0: 275 [D loss: 2.408, acc:  45] [G loss: 0.047]\n",
      " 0: 276 [D loss: 2.483, acc:  44] [G loss: 0.059]\n",
      " 0: 277 [D loss: 2.464, acc:  45] [G loss: 0.050]\n",
      " 0: 278 [D loss: 2.260, acc:  48] [G loss: 0.068]\n",
      " 0: 279 [D loss: 2.404, acc:  48] [G loss: 0.044]\n",
      " 0: 280 [D loss: 2.318, acc:  42] [G loss: 0.054]\n",
      " 0: 281 [D loss: 2.370, acc:  48] [G loss: 0.053]\n",
      " 0: 282 [D loss: 2.260, acc:  50] [G loss: 0.049]\n",
      " 0: 283 [D loss: 2.223, acc:  47] [G loss: 0.069]\n",
      " 0: 284 [D loss: 2.382, acc:  47] [G loss: 0.065]\n",
      " 0: 285 [D loss: 2.354, acc:  47] [G loss: 0.056]\n",
      " 0: 286 [D loss: 2.439, acc:  45] [G loss: 0.054]\n",
      " 0: 287 [D loss: 2.369, acc:  42] [G loss: 0.052]\n",
      " 0: 288 [D loss: 2.278, acc:  50] [G loss: 0.054]\n",
      " 0: 289 [D loss: 2.423, acc:  45] [G loss: 0.059]\n",
      " 0: 290 [D loss: 2.327, acc:  48] [G loss: 0.053]\n",
      " 0: 291 [D loss: 2.441, acc:  42] [G loss: 0.044]\n",
      " 0: 292 [D loss: 2.343, acc:  45] [G loss: 0.060]\n",
      " 0: 293 [D loss: 2.315, acc:  42] [G loss: 0.050]\n",
      " 0: 294 [D loss: 2.253, acc:  45] [G loss: 0.059]\n",
      " 0: 295 [D loss: 2.210, acc:  48] [G loss: 0.055]\n",
      " 0: 296 [D loss: 2.352, acc:  45] [G loss: 0.070]\n",
      " 0: 297 [D loss: 2.281, acc:  45] [G loss: 0.063]\n",
      " 0: 298 [D loss: 2.198, acc:  48] [G loss: 0.059]\n",
      " 0: 299 [D loss: 2.108, acc:  48] [G loss: 0.064]\n",
      " 0: 300 [D loss: 2.188, acc:  48] [G loss: 0.059]\n",
      " 0: 301 [D loss: 2.214, acc:  45] [G loss: 0.071]\n",
      " 0: 302 [D loss: 2.232, acc:  48] [G loss: 0.079]\n",
      " 0: 303 [D loss: 2.084, acc:  48] [G loss: 0.053]\n",
      " 0: 304 [D loss: 2.239, acc:  45] [G loss: 0.061]\n",
      " 0: 305 [D loss: 2.228, acc:  48] [G loss: 0.068]\n",
      " 0: 306 [D loss: 2.066, acc:  50] [G loss: 0.073]\n",
      " 0: 307 [D loss: 2.037, acc:  50] [G loss: 0.068]\n",
      " 0: 308 [D loss: 2.069, acc:  45] [G loss: 0.077]\n",
      " 0: 309 [D loss: 2.052, acc:  50] [G loss: 0.066]\n",
      " 0: 310 [D loss: 2.055, acc:  45] [G loss: 0.069]\n",
      " 0: 311 [D loss: 2.079, acc:  47] [G loss: 0.066]\n",
      " 0: 312 [D loss: 2.046, acc:  47] [G loss: 0.057]\n",
      " 0: 313 [D loss: 2.074, acc:  50] [G loss: 0.070]\n",
      " 0: 314 [D loss: 2.144, acc:  44] [G loss: 0.072]\n",
      " 0: 315 [D loss: 2.054, acc:  48] [G loss: 0.063]\n",
      " 0: 316 [D loss: 2.159, acc:  47] [G loss: 0.071]\n",
      " 0: 317 [D loss: 2.149, acc:  45] [G loss: 0.070]\n",
      " 0: 318 [D loss: 2.111, acc:  47] [G loss: 0.068]\n",
      " 0: 319 [D loss: 2.286, acc:  41] [G loss: 0.069]\n",
      " 0: 320 [D loss: 1.995, acc:  47] [G loss: 0.073]\n",
      " 0: 321 [D loss: 2.030, acc:  47] [G loss: 0.084]\n",
      " 0: 322 [D loss: 1.999, acc:  45] [G loss: 0.065]\n",
      " 0: 323 [D loss: 2.142, acc:  44] [G loss: 0.070]\n",
      " 0: 324 [D loss: 1.981, acc:  47] [G loss: 0.083]\n",
      " 0: 325 [D loss: 2.115, acc:  45] [G loss: 0.099]\n",
      " 0: 326 [D loss: 1.987, acc:  45] [G loss: 0.093]\n",
      " 0: 327 [D loss: 2.062, acc:  44] [G loss: 0.082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: 328 [D loss: 1.987, acc:  47] [G loss: 0.082]\n",
      " 0: 329 [D loss: 1.783, acc:  50] [G loss: 0.086]\n",
      " 0: 330 [D loss: 1.918, acc:  47] [G loss: 0.078]\n",
      " 0: 331 [D loss: 1.993, acc:  48] [G loss: 0.075]\n",
      " 0: 332 [D loss: 1.874, acc:  48] [G loss: 0.079]\n",
      " 0: 333 [D loss: 2.067, acc:  45] [G loss: 0.078]\n",
      " 0: 334 [D loss: 1.881, acc:  48] [G loss: 0.073]\n",
      " 0: 335 [D loss: 2.017, acc:  45] [G loss: 0.084]\n",
      " 0: 336 [D loss: 2.031, acc:  48] [G loss: 0.084]\n",
      " 0: 337 [D loss: 1.993, acc:  44] [G loss: 0.080]\n",
      " 0: 338 [D loss: 1.897, acc:  47] [G loss: 0.086]\n",
      " 0: 339 [D loss: 1.894, acc:  47] [G loss: 0.096]\n",
      " 0: 340 [D loss: 1.871, acc:  47] [G loss: 0.092]\n",
      " 0: 341 [D loss: 1.780, acc:  48] [G loss: 0.084]\n",
      " 0: 342 [D loss: 1.850, acc:  48] [G loss: 0.085]\n",
      " 0: 343 [D loss: 1.940, acc:  47] [G loss: 0.090]\n",
      " 0: 344 [D loss: 2.289, acc:  34] [G loss: 0.091]\n",
      " 0: 345 [D loss: 1.814, acc:  48] [G loss: 0.081]\n",
      " 0: 346 [D loss: 1.928, acc:  45] [G loss: 0.081]\n",
      " 0: 347 [D loss: 1.930, acc:  45] [G loss: 0.094]\n",
      " 0: 348 [D loss: 1.931, acc:  45] [G loss: 0.094]\n",
      " 0: 349 [D loss: 1.891, acc:  48] [G loss: 0.093]\n",
      " 0: 350 [D loss: 1.793, acc:  44] [G loss: 0.091]\n",
      " 0: 351 [D loss: 1.877, acc:  48] [G loss: 0.093]\n",
      " 0: 352 [D loss: 1.818, acc:  47] [G loss: 0.100]\n",
      " 0: 353 [D loss: 1.950, acc:  42] [G loss: 0.085]\n",
      " 0: 354 [D loss: 1.690, acc:  50] [G loss: 0.095]\n",
      " 0: 355 [D loss: 1.936, acc:  42] [G loss: 0.101]\n",
      " 0: 356 [D loss: 1.767, acc:  47] [G loss: 0.102]\n",
      " 0: 357 [D loss: 1.760, acc:  48] [G loss: 0.102]\n",
      " 0: 358 [D loss: 1.842, acc:  42] [G loss: 0.085]\n",
      " 0: 359 [D loss: 1.948, acc:  44] [G loss: 0.113]\n",
      " 0: 360 [D loss: 1.921, acc:  47] [G loss: 0.109]\n",
      " 0: 361 [D loss: 2.087, acc:  39] [G loss: 0.095]\n",
      " 0: 362 [D loss: 1.704, acc:  47] [G loss: 0.102]\n",
      " 0: 363 [D loss: 1.815, acc:  47] [G loss: 0.092]\n",
      " 0: 364 [D loss: 1.740, acc:  44] [G loss: 0.088]\n",
      " 0: 365 [D loss: 1.777, acc:  45] [G loss: 0.102]\n",
      " 0: 366 [D loss: 1.674, acc:  50] [G loss: 0.102]\n",
      " 0: 367 [D loss: 1.826, acc:  42] [G loss: 0.112]\n",
      " 0: 368 [D loss: 1.761, acc:  45] [G loss: 0.100]\n",
      " 0: 369 [D loss: 1.579, acc:  48] [G loss: 0.103]\n",
      " 0: 370 [D loss: 1.690, acc:  48] [G loss: 0.100]\n",
      " 0: 371 [D loss: 1.767, acc:  44] [G loss: 0.113]\n",
      " 0: 372 [D loss: 1.519, acc:  48] [G loss: 0.092]\n",
      " 0: 373 [D loss: 1.688, acc:  45] [G loss: 0.097]\n",
      " 0: 374 [D loss: 1.757, acc:  45] [G loss: 0.104]\n",
      " 0: 375 [D loss: 1.638, acc:  50] [G loss: 0.117]\n",
      " 0: 376 [D loss: 1.665, acc:  47] [G loss: 0.106]\n",
      " 0: 377 [D loss: 1.665, acc:  44] [G loss: 0.114]\n",
      " 0: 378 [D loss: 1.536, acc:  48] [G loss: 0.105]\n",
      " 0: 379 [D loss: 1.757, acc:  44] [G loss: 0.110]\n",
      " 0: 380 [D loss: 1.689, acc:  45] [G loss: 0.103]\n",
      " 0: 381 [D loss: 1.719, acc:  42] [G loss: 0.135]\n",
      " 0: 382 [D loss: 1.672, acc:  44] [G loss: 0.114]\n",
      " 0: 383 [D loss: 1.839, acc:  44] [G loss: 0.121]\n",
      " 0: 384 [D loss: 1.607, acc:  45] [G loss: 0.106]\n",
      " 0: 385 [D loss: 1.784, acc:  44] [G loss: 0.121]\n",
      " 0: 386 [D loss: 1.653, acc:  44] [G loss: 0.114]\n",
      " 0: 387 [D loss: 1.630, acc:  45] [G loss: 0.104]\n",
      " 0: 388 [D loss: 1.639, acc:  47] [G loss: 0.106]\n",
      " 0: 389 [D loss: 1.571, acc:  47] [G loss: 0.116]\n",
      " 0: 390 [D loss: 1.681, acc:  42] [G loss: 0.117]\n",
      " 0: 391 [D loss: 1.617, acc:  48] [G loss: 0.111]\n",
      " 0: 392 [D loss: 1.600, acc:  45] [G loss: 0.118]\n",
      " 0: 393 [D loss: 1.578, acc:  45] [G loss: 0.119]\n",
      " 0: 394 [D loss: 1.546, acc:  45] [G loss: 0.123]\n",
      " 0: 395 [D loss: 1.737, acc:  45] [G loss: 0.133]\n",
      " 0: 396 [D loss: 1.554, acc:  45] [G loss: 0.140]\n",
      " 0: 397 [D loss: 1.638, acc:  47] [G loss: 0.121]\n",
      " 0: 398 [D loss: 1.747, acc:  41] [G loss: 0.123]\n",
      " 0: 399 [D loss: 1.573, acc:  45] [G loss: 0.127]\n",
      " 0: 400 [D loss: 1.621, acc:  41] [G loss: 0.118]\n",
      " 0: 401 [D loss: 1.652, acc:  45] [G loss: 0.125]\n",
      " 0: 402 [D loss: 1.607, acc:  47] [G loss: 0.137]\n",
      " 0: 403 [D loss: 1.433, acc:  48] [G loss: 0.131]\n",
      " 0: 404 [D loss: 1.578, acc:  44] [G loss: 0.130]\n",
      " 0: 405 [D loss: 1.641, acc:  39] [G loss: 0.130]\n",
      " 0: 406 [D loss: 1.536, acc:  44] [G loss: 0.122]\n",
      " 0: 407 [D loss: 1.620, acc:  44] [G loss: 0.118]\n",
      " 0: 408 [D loss: 1.648, acc:  47] [G loss: 0.142]\n",
      " 0: 409 [D loss: 1.596, acc:  47] [G loss: 0.135]\n",
      " 0: 410 [D loss: 1.459, acc:  50] [G loss: 0.126]\n",
      " 0: 411 [D loss: 1.609, acc:  44] [G loss: 0.121]\n",
      " 0: 412 [D loss: 1.703, acc:  41] [G loss: 0.126]\n",
      " 0: 413 [D loss: 1.436, acc:  47] [G loss: 0.134]\n",
      " 0: 414 [D loss: 1.646, acc:  44] [G loss: 0.124]\n",
      " 0: 415 [D loss: 1.399, acc:  50] [G loss: 0.115]\n",
      " 0: 416 [D loss: 1.858, acc:  41] [G loss: 0.137]\n",
      " 0: 417 [D loss: 1.476, acc:  47] [G loss: 0.130]\n",
      " 0: 418 [D loss: 1.439, acc:  50] [G loss: 0.128]\n",
      " 0: 419 [D loss: 1.686, acc:  44] [G loss: 0.139]\n",
      " 0: 420 [D loss: 1.491, acc:  42] [G loss: 0.137]\n",
      " 0: 421 [D loss: 1.609, acc:  45] [G loss: 0.149]\n",
      " 0: 422 [D loss: 1.493, acc:  44] [G loss: 0.135]\n",
      " 0: 423 [D loss: 1.556, acc:  48] [G loss: 0.139]\n",
      " 1:   0 [D loss: 1.727, acc:  45] [G loss: 0.137]\n",
      " 1:   1 [D loss: 1.478, acc:  45] [G loss: 0.125]\n",
      " 1:   2 [D loss: 1.404, acc:  45] [G loss: 0.137]\n",
      " 1:   3 [D loss: 1.433, acc:  47] [G loss: 0.140]\n",
      " 1:   4 [D loss: 1.597, acc:  42] [G loss: 0.131]\n",
      " 1:   5 [D loss: 1.471, acc:  47] [G loss: 0.153]\n",
      " 1:   6 [D loss: 1.417, acc:  47] [G loss: 0.122]\n",
      " 1:   7 [D loss: 1.428, acc:  48] [G loss: 0.141]\n",
      " 1:   8 [D loss: 1.553, acc:  47] [G loss: 0.127]\n",
      " 1:   9 [D loss: 1.830, acc:  42] [G loss: 0.140]\n",
      " 1:  10 [D loss: 1.434, acc:  44] [G loss: 0.139]\n",
      " 1:  11 [D loss: 1.431, acc:  45] [G loss: 0.139]\n",
      " 1:  12 [D loss: 1.351, acc:  48] [G loss: 0.136]\n",
      " 1:  13 [D loss: 1.543, acc:  45] [G loss: 0.137]\n",
      " 1:  14 [D loss: 1.753, acc:  42] [G loss: 0.145]\n",
      " 1:  15 [D loss: 1.665, acc:  44] [G loss: 0.139]\n",
      " 1:  16 [D loss: 1.503, acc:  42] [G loss: 0.135]\n",
      " 1:  17 [D loss: 1.374, acc:  48] [G loss: 0.137]\n",
      " 1:  18 [D loss: 1.497, acc:  47] [G loss: 0.128]\n",
      " 1:  19 [D loss: 1.429, acc:  47] [G loss: 0.159]\n",
      " 1:  20 [D loss: 1.414, acc:  48] [G loss: 0.144]\n",
      " 1:  21 [D loss: 1.396, acc:  48] [G loss: 0.131]\n",
      " 1:  22 [D loss: 1.336, acc:  47] [G loss: 0.141]\n",
      " 1:  23 [D loss: 1.421, acc:  47] [G loss: 0.149]\n",
      " 1:  24 [D loss: 1.383, acc:  47] [G loss: 0.151]\n",
      " 1:  25 [D loss: 1.388, acc:  47] [G loss: 0.131]\n",
      " 1:  26 [D loss: 1.773, acc:  39] [G loss: 0.123]\n",
      " 1:  27 [D loss: 1.511, acc:  42] [G loss: 0.140]\n",
      " 1:  28 [D loss: 1.319, acc:  48] [G loss: 0.145]\n",
      " 1:  29 [D loss: 1.529, acc:  45] [G loss: 0.154]\n",
      " 1:  30 [D loss: 1.342, acc:  47] [G loss: 0.146]\n",
      " 1:  31 [D loss: 1.538, acc:  44] [G loss: 0.132]\n",
      " 1:  32 [D loss: 1.389, acc:  45] [G loss: 0.137]\n",
      " 1:  33 [D loss: 1.390, acc:  45] [G loss: 0.136]\n",
      " 1:  34 [D loss: 1.890, acc:  41] [G loss: 0.158]\n",
      " 1:  35 [D loss: 1.516, acc:  45] [G loss: 0.135]\n",
      " 1:  36 [D loss: 1.421, acc:  47] [G loss: 0.150]\n",
      " 1:  37 [D loss: 1.430, acc:  45] [G loss: 0.147]\n",
      " 1:  38 [D loss: 1.370, acc:  47] [G loss: 0.134]\n",
      " 1:  39 [D loss: 1.612, acc:  47] [G loss: 0.154]\n",
      " 1:  40 [D loss: 1.668, acc:  45] [G loss: 0.147]\n",
      " 1:  41 [D loss: 1.499, acc:  48] [G loss: 0.155]\n",
      " 1:  42 [D loss: 1.373, acc:  47] [G loss: 0.131]\n",
      " 1:  43 [D loss: 1.419, acc:  48] [G loss: 0.146]\n",
      " 1:  44 [D loss: 1.454, acc:  44] [G loss: 0.160]\n",
      " 1:  45 [D loss: 1.521, acc:  45] [G loss: 0.151]\n",
      " 1:  46 [D loss: 1.676, acc:  39] [G loss: 0.142]\n",
      " 1:  47 [D loss: 1.453, acc:  45] [G loss: 0.149]\n",
      " 1:  48 [D loss: 1.298, acc:  45] [G loss: 0.137]\n",
      " 1:  49 [D loss: 1.340, acc:  50] [G loss: 0.150]\n",
      " 1:  50 [D loss: 1.512, acc:  44] [G loss: 0.147]\n",
      " 1:  51 [D loss: 1.350, acc:  48] [G loss: 0.139]\n",
      " 1:  52 [D loss: 1.487, acc:  44] [G loss: 0.154]\n",
      " 1:  53 [D loss: 1.381, acc:  47] [G loss: 0.140]\n",
      " 1:  54 [D loss: 1.412, acc:  44] [G loss: 0.138]\n",
      " 1:  55 [D loss: 1.422, acc:  44] [G loss: 0.137]\n",
      " 1:  56 [D loss: 1.790, acc:  42] [G loss: 0.137]\n",
      " 1:  57 [D loss: 1.341, acc:  48] [G loss: 0.153]\n",
      " 1:  58 [D loss: 1.454, acc:  42] [G loss: 0.163]\n",
      " 1:  59 [D loss: 1.505, acc:  44] [G loss: 0.142]\n",
      " 1:  60 [D loss: 1.549, acc:  42] [G loss: 0.148]\n",
      " 1:  61 [D loss: 1.445, acc:  44] [G loss: 0.137]\n",
      " 1:  62 [D loss: 1.582, acc:  44] [G loss: 0.143]\n",
      " 1:  63 [D loss: 1.290, acc:  45] [G loss: 0.147]\n",
      " 1:  64 [D loss: 1.409, acc:  47] [G loss: 0.134]\n",
      " 1:  65 [D loss: 1.479, acc:  47] [G loss: 0.146]\n",
      " 1:  66 [D loss: 1.464, acc:  47] [G loss: 0.151]\n",
      " 1:  67 [D loss: 1.489, acc:  42] [G loss: 0.137]\n",
      " 1:  68 [D loss: 1.319, acc:  47] [G loss: 0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1:  69 [D loss: 1.316, acc:  48] [G loss: 0.144]\n",
      " 1:  70 [D loss: 1.465, acc:  41] [G loss: 0.132]\n",
      " 1:  71 [D loss: 1.603, acc:  42] [G loss: 0.139]\n",
      " 1:  72 [D loss: 1.705, acc:  44] [G loss: 0.145]\n",
      " 1:  73 [D loss: 1.402, acc:  48] [G loss: 0.142]\n",
      " 1:  74 [D loss: 1.322, acc:  47] [G loss: 0.149]\n",
      " 1:  75 [D loss: 1.351, acc:  45] [G loss: 0.139]\n",
      " 1:  76 [D loss: 1.384, acc:  45] [G loss: 0.151]\n",
      " 1:  77 [D loss: 1.335, acc:  47] [G loss: 0.140]\n",
      " 1:  78 [D loss: 1.405, acc:  47] [G loss: 0.153]\n",
      " 1:  79 [D loss: 1.375, acc:  47] [G loss: 0.139]\n",
      " 1:  80 [D loss: 1.390, acc:  48] [G loss: 0.148]\n",
      " 1:  81 [D loss: 1.392, acc:  42] [G loss: 0.145]\n",
      " 1:  82 [D loss: 1.632, acc:  42] [G loss: 0.137]\n",
      " 1:  83 [D loss: 1.308, acc:  47] [G loss: 0.138]\n",
      " 1:  84 [D loss: 1.376, acc:  47] [G loss: 0.145]\n",
      " 1:  85 [D loss: 1.555, acc:  44] [G loss: 0.144]\n",
      " 1:  86 [D loss: 1.564, acc:  41] [G loss: 0.139]\n",
      " 1:  87 [D loss: 1.370, acc:  47] [G loss: 0.141]\n",
      " 1:  88 [D loss: 1.414, acc:  42] [G loss: 0.151]\n",
      " 1:  89 [D loss: 1.370, acc:  42] [G loss: 0.147]\n",
      " 1:  90 [D loss: 1.248, acc:  50] [G loss: 0.138]\n",
      " 1:  91 [D loss: 1.529, acc:  47] [G loss: 0.141]\n",
      " 1:  92 [D loss: 1.367, acc:  44] [G loss: 0.148]\n",
      " 1:  93 [D loss: 1.430, acc:  47] [G loss: 0.149]\n",
      " 1:  94 [D loss: 1.440, acc:  44] [G loss: 0.137]\n",
      " 1:  95 [D loss: 1.776, acc:  42] [G loss: 0.144]\n",
      " 1:  96 [D loss: 1.604, acc:  42] [G loss: 0.140]\n",
      " 1:  97 [D loss: 1.461, acc:  42] [G loss: 0.138]\n",
      " 1:  98 [D loss: 1.245, acc:  50] [G loss: 0.131]\n",
      " 1:  99 [D loss: 1.400, acc:  48] [G loss: 0.143]\n",
      " 1: 100 [D loss: 1.319, acc:  47] [G loss: 0.144]\n",
      " 1: 101 [D loss: 1.701, acc:  42] [G loss: 0.137]\n",
      " 1: 102 [D loss: 1.447, acc:  42] [G loss: 0.143]\n",
      " 1: 103 [D loss: 1.401, acc:  44] [G loss: 0.136]\n",
      " 1: 104 [D loss: 1.544, acc:  44] [G loss: 0.141]\n",
      " 1: 105 [D loss: 1.396, acc:  48] [G loss: 0.135]\n",
      " 1: 106 [D loss: 1.351, acc:  47] [G loss: 0.150]\n",
      " 1: 107 [D loss: 1.300, acc:  47] [G loss: 0.148]\n",
      " 1: 108 [D loss: 1.416, acc:  45] [G loss: 0.130]\n",
      " 1: 109 [D loss: 1.694, acc:  41] [G loss: 0.143]\n",
      " 1: 110 [D loss: 1.368, acc:  47] [G loss: 0.145]\n",
      " 1: 111 [D loss: 1.525, acc:  45] [G loss: 0.149]\n",
      " 1: 112 [D loss: 1.328, acc:  45] [G loss: 0.151]\n",
      " 1: 113 [D loss: 1.324, acc:  45] [G loss: 0.141]\n",
      " 1: 114 [D loss: 1.600, acc:  44] [G loss: 0.132]\n",
      " 1: 115 [D loss: 1.327, acc:  45] [G loss: 0.145]\n",
      " 1: 116 [D loss: 1.353, acc:  48] [G loss: 0.139]\n",
      " 1: 117 [D loss: 1.464, acc:  44] [G loss: 0.136]\n",
      " 1: 118 [D loss: 1.543, acc:  44] [G loss: 0.138]\n",
      " 1: 119 [D loss: 1.506, acc:  47] [G loss: 0.142]\n",
      " 1: 120 [D loss: 1.505, acc:  45] [G loss: 0.143]\n",
      " 1: 121 [D loss: 1.736, acc:  39] [G loss: 0.141]\n",
      " 1: 122 [D loss: 1.790, acc:  41] [G loss: 0.148]\n",
      " 1: 123 [D loss: 1.596, acc:  44] [G loss: 0.144]\n",
      " 1: 124 [D loss: 1.518, acc:  44] [G loss: 0.136]\n",
      " 1: 125 [D loss: 1.283, acc:  50] [G loss: 0.139]\n",
      " 1: 126 [D loss: 1.474, acc:  42] [G loss: 0.145]\n",
      " 1: 127 [D loss: 1.332, acc:  44] [G loss: 0.137]\n",
      " 1: 128 [D loss: 1.564, acc:  41] [G loss: 0.137]\n",
      " 1: 129 [D loss: 1.614, acc:  42] [G loss: 0.145]\n",
      " 1: 130 [D loss: 1.472, acc:  41] [G loss: 0.139]\n",
      " 1: 131 [D loss: 1.453, acc:  45] [G loss: 0.133]\n",
      " 1: 132 [D loss: 1.485, acc:  42] [G loss: 0.141]\n",
      " 1: 133 [D loss: 1.419, acc:  45] [G loss: 0.142]\n",
      " 1: 134 [D loss: 1.657, acc:  39] [G loss: 0.134]\n",
      " 1: 135 [D loss: 1.391, acc:  47] [G loss: 0.141]\n",
      " 1: 136 [D loss: 1.416, acc:  44] [G loss: 0.131]\n",
      " 1: 137 [D loss: 1.326, acc:  47] [G loss: 0.139]\n",
      " 1: 138 [D loss: 1.652, acc:  39] [G loss: 0.139]\n",
      " 1: 139 [D loss: 1.360, acc:  44] [G loss: 0.136]\n",
      " 1: 140 [D loss: 1.359, acc:  47] [G loss: 0.146]\n",
      " 1: 141 [D loss: 1.234, acc:  50] [G loss: 0.146]\n",
      " 1: 142 [D loss: 1.275, acc:  47] [G loss: 0.141]\n",
      " 1: 143 [D loss: 1.550, acc:  42] [G loss: 0.140]\n",
      " 1: 144 [D loss: 1.545, acc:  41] [G loss: 0.134]\n",
      " 1: 145 [D loss: 1.319, acc:  44] [G loss: 0.145]\n",
      " 1: 146 [D loss: 1.534, acc:  42] [G loss: 0.138]\n",
      " 1: 147 [D loss: 1.254, acc:  48] [G loss: 0.145]\n",
      " 1: 148 [D loss: 1.291, acc:  48] [G loss: 0.142]\n",
      " 1: 149 [D loss: 1.397, acc:  38] [G loss: 0.144]\n",
      " 1: 150 [D loss: 1.499, acc:  41] [G loss: 0.149]\n",
      " 1: 151 [D loss: 1.490, acc:  45] [G loss: 0.147]\n",
      " 1: 152 [D loss: 1.327, acc:  45] [G loss: 0.135]\n",
      " 1: 153 [D loss: 1.254, acc:  47] [G loss: 0.143]\n",
      " 1: 154 [D loss: 1.248, acc:  47] [G loss: 0.140]\n",
      " 1: 155 [D loss: 1.454, acc:  42] [G loss: 0.156]\n",
      " 1: 156 [D loss: 1.230, acc:  48] [G loss: 0.151]\n",
      " 1: 157 [D loss: 1.383, acc:  47] [G loss: 0.148]\n",
      " 1: 158 [D loss: 1.473, acc:  44] [G loss: 0.146]\n",
      " 1: 159 [D loss: 1.326, acc:  45] [G loss: 0.142]\n",
      " 1: 160 [D loss: 1.393, acc:  44] [G loss: 0.150]\n",
      " 1: 161 [D loss: 1.260, acc:  47] [G loss: 0.145]\n",
      " 1: 162 [D loss: 1.307, acc:  45] [G loss: 0.163]\n",
      " 1: 163 [D loss: 1.397, acc:  45] [G loss: 0.146]\n",
      " 1: 164 [D loss: 1.646, acc:  38] [G loss: 0.151]\n",
      " 1: 165 [D loss: 1.356, acc:  42] [G loss: 0.154]\n",
      " 1: 166 [D loss: 1.355, acc:  44] [G loss: 0.149]\n",
      " 1: 167 [D loss: 1.416, acc:  45] [G loss: 0.140]\n",
      " 1: 168 [D loss: 1.360, acc:  45] [G loss: 0.146]\n",
      " 1: 169 [D loss: 1.315, acc:  44] [G loss: 0.149]\n",
      " 1: 170 [D loss: 1.240, acc:  47] [G loss: 0.142]\n",
      " 1: 171 [D loss: 1.325, acc:  47] [G loss: 0.152]\n",
      " 1: 172 [D loss: 1.427, acc:  44] [G loss: 0.146]\n",
      " 1: 173 [D loss: 1.241, acc:  45] [G loss: 0.141]\n",
      " 1: 174 [D loss: 1.372, acc:  42] [G loss: 0.154]\n",
      " 1: 175 [D loss: 1.558, acc:  45] [G loss: 0.162]\n",
      " 1: 176 [D loss: 1.382, acc:  47] [G loss: 0.149]\n",
      " 1: 177 [D loss: 1.256, acc:  47] [G loss: 0.148]\n",
      " 1: 178 [D loss: 1.296, acc:  41] [G loss: 0.151]\n",
      " 1: 179 [D loss: 1.274, acc:  47] [G loss: 0.152]\n",
      " 1: 180 [D loss: 1.405, acc:  44] [G loss: 0.152]\n",
      " 1: 181 [D loss: 1.699, acc:  41] [G loss: 0.157]\n",
      " 1: 182 [D loss: 1.448, acc:  42] [G loss: 0.148]\n",
      " 1: 183 [D loss: 1.333, acc:  45] [G loss: 0.149]\n",
      " 1: 184 [D loss: 1.326, acc:  47] [G loss: 0.155]\n",
      " 1: 185 [D loss: 1.201, acc:  50] [G loss: 0.160]\n",
      " 1: 186 [D loss: 1.234, acc:  47] [G loss: 0.148]\n",
      " 1: 187 [D loss: 1.410, acc:  44] [G loss: 0.162]\n",
      " 1: 188 [D loss: 1.477, acc:  41] [G loss: 0.146]\n",
      " 1: 189 [D loss: 1.250, acc:  45] [G loss: 0.148]\n",
      " 1: 190 [D loss: 1.367, acc:  45] [G loss: 0.162]\n",
      " 1: 191 [D loss: 1.294, acc:  45] [G loss: 0.161]\n",
      " 1: 192 [D loss: 1.449, acc:  42] [G loss: 0.151]\n",
      " 1: 193 [D loss: 1.247, acc:  45] [G loss: 0.158]\n",
      " 1: 194 [D loss: 1.312, acc:  47] [G loss: 0.148]\n",
      " 1: 195 [D loss: 1.294, acc:  45] [G loss: 0.148]\n",
      " 1: 196 [D loss: 1.571, acc:  39] [G loss: 0.151]\n",
      " 1: 197 [D loss: 1.389, acc:  42] [G loss: 0.150]\n",
      " 1: 198 [D loss: 1.390, acc:  44] [G loss: 0.150]\n",
      " 1: 199 [D loss: 1.178, acc:  48] [G loss: 0.152]\n",
      " 1: 200 [D loss: 1.280, acc:  44] [G loss: 0.154]\n",
      " 1: 201 [D loss: 1.446, acc:  47] [G loss: 0.154]\n",
      " 1: 202 [D loss: 1.305, acc:  45] [G loss: 0.158]\n",
      " 1: 203 [D loss: 1.294, acc:  45] [G loss: 0.156]\n",
      " 1: 204 [D loss: 1.242, acc:  45] [G loss: 0.150]\n",
      " 1: 205 [D loss: 1.450, acc:  44] [G loss: 0.173]\n",
      " 1: 206 [D loss: 1.317, acc:  44] [G loss: 0.151]\n",
      " 1: 207 [D loss: 1.246, acc:  45] [G loss: 0.154]\n",
      " 1: 208 [D loss: 1.390, acc:  44] [G loss: 0.158]\n",
      " 1: 209 [D loss: 1.434, acc:  39] [G loss: 0.155]\n",
      " 1: 210 [D loss: 1.346, acc:  44] [G loss: 0.159]\n",
      " 1: 211 [D loss: 1.388, acc:  44] [G loss: 0.172]\n",
      " 1: 212 [D loss: 1.323, acc:  44] [G loss: 0.157]\n",
      " 1: 213 [D loss: 1.169, acc:  47] [G loss: 0.160]\n",
      " 1: 214 [D loss: 1.203, acc:  48] [G loss: 0.158]\n",
      " 1: 215 [D loss: 1.347, acc:  44] [G loss: 0.152]\n",
      " 1: 216 [D loss: 1.545, acc:  41] [G loss: 0.159]\n",
      " 1: 217 [D loss: 1.166, acc:  47] [G loss: 0.160]\n",
      " 1: 218 [D loss: 1.380, acc:  41] [G loss: 0.158]\n",
      " 1: 219 [D loss: 1.258, acc:  44] [G loss: 0.159]\n",
      " 1: 220 [D loss: 1.285, acc:  44] [G loss: 0.160]\n",
      " 1: 221 [D loss: 1.229, acc:  45] [G loss: 0.156]\n",
      " 1: 222 [D loss: 1.439, acc:  44] [G loss: 0.164]\n",
      " 1: 223 [D loss: 1.340, acc:  44] [G loss: 0.167]\n",
      " 1: 224 [D loss: 1.224, acc:  45] [G loss: 0.161]\n",
      " 1: 225 [D loss: 1.186, acc:  47] [G loss: 0.155]\n",
      " 1: 226 [D loss: 1.224, acc:  47] [G loss: 0.165]\n",
      " 1: 227 [D loss: 1.453, acc:  41] [G loss: 0.156]\n",
      " 1: 228 [D loss: 1.278, acc:  44] [G loss: 0.165]\n",
      " 1: 229 [D loss: 1.460, acc:  41] [G loss: 0.167]\n",
      " 1: 230 [D loss: 1.259, acc:  42] [G loss: 0.156]\n",
      " 1: 231 [D loss: 1.125, acc:  50] [G loss: 0.155]\n",
      " 1: 232 [D loss: 1.308, acc:  44] [G loss: 0.153]\n",
      " 1: 233 [D loss: 1.176, acc:  48] [G loss: 0.157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: 234 [D loss: 1.487, acc:  41] [G loss: 0.173]\n",
      " 1: 235 [D loss: 1.396, acc:  45] [G loss: 0.152]\n",
      " 1: 236 [D loss: 1.469, acc:  45] [G loss: 0.156]\n",
      " 1: 237 [D loss: 1.343, acc:  42] [G loss: 0.158]\n",
      " 1: 238 [D loss: 1.214, acc:  45] [G loss: 0.159]\n",
      " 1: 239 [D loss: 1.318, acc:  45] [G loss: 0.157]\n",
      " 1: 240 [D loss: 1.283, acc:  48] [G loss: 0.162]\n",
      " 1: 241 [D loss: 1.181, acc:  47] [G loss: 0.164]\n",
      " 1: 242 [D loss: 1.202, acc:  44] [G loss: 0.161]\n",
      " 1: 243 [D loss: 1.486, acc:  41] [G loss: 0.158]\n",
      " 1: 244 [D loss: 1.508, acc:  42] [G loss: 0.174]\n",
      " 1: 245 [D loss: 1.210, acc:  45] [G loss: 0.163]\n",
      " 1: 246 [D loss: 1.207, acc:  47] [G loss: 0.172]\n",
      " 1: 247 [D loss: 1.153, acc:  47] [G loss: 0.157]\n",
      " 1: 248 [D loss: 1.184, acc:  47] [G loss: 0.172]\n",
      " 1: 249 [D loss: 1.298, acc:  41] [G loss: 0.166]\n",
      " 1: 250 [D loss: 1.414, acc:  42] [G loss: 0.160]\n",
      " 1: 251 [D loss: 1.442, acc:  42] [G loss: 0.160]\n",
      " 1: 252 [D loss: 1.192, acc:  47] [G loss: 0.168]\n",
      " 1: 253 [D loss: 1.193, acc:  47] [G loss: 0.166]\n",
      " 1: 254 [D loss: 1.237, acc:  45] [G loss: 0.164]\n",
      " 1: 255 [D loss: 1.260, acc:  42] [G loss: 0.156]\n",
      " 1: 256 [D loss: 1.262, acc:  44] [G loss: 0.163]\n",
      " 1: 257 [D loss: 1.169, acc:  48] [G loss: 0.164]\n",
      " 1: 258 [D loss: 1.473, acc:  39] [G loss: 0.163]\n",
      " 1: 259 [D loss: 1.353, acc:  44] [G loss: 0.159]\n",
      " 1: 260 [D loss: 1.209, acc:  45] [G loss: 0.161]\n",
      " 1: 261 [D loss: 1.224, acc:  47] [G loss: 0.166]\n",
      " 1: 262 [D loss: 1.267, acc:  41] [G loss: 0.166]\n",
      " 1: 263 [D loss: 1.156, acc:  48] [G loss: 0.162]\n",
      " 1: 264 [D loss: 1.125, acc:  48] [G loss: 0.166]\n",
      " 1: 265 [D loss: 1.378, acc:  42] [G loss: 0.159]\n",
      " 1: 266 [D loss: 1.312, acc:  42] [G loss: 0.171]\n",
      " 1: 267 [D loss: 1.184, acc:  47] [G loss: 0.168]\n",
      " 1: 268 [D loss: 1.191, acc:  47] [G loss: 0.167]\n",
      " 1: 269 [D loss: 1.443, acc:  44] [G loss: 0.164]\n",
      " 1: 270 [D loss: 1.265, acc:  44] [G loss: 0.168]\n",
      " 1: 271 [D loss: 1.220, acc:  45] [G loss: 0.177]\n",
      " 1: 272 [D loss: 1.111, acc:  47] [G loss: 0.171]\n",
      " 1: 273 [D loss: 1.373, acc:  39] [G loss: 0.166]\n",
      " 1: 274 [D loss: 1.251, acc:  45] [G loss: 0.172]\n",
      " 1: 275 [D loss: 1.192, acc:  45] [G loss: 0.165]\n",
      " 1: 276 [D loss: 1.374, acc:  42] [G loss: 0.164]\n",
      " 1: 277 [D loss: 1.242, acc:  45] [G loss: 0.166]\n",
      " 1: 278 [D loss: 1.183, acc:  47] [G loss: 0.170]\n",
      " 1: 279 [D loss: 1.266, acc:  47] [G loss: 0.165]\n",
      " 1: 280 [D loss: 1.234, acc:  42] [G loss: 0.168]\n",
      " 1: 281 [D loss: 1.165, acc:  48] [G loss: 0.175]\n",
      " 1: 282 [D loss: 1.110, acc:  50] [G loss: 0.169]\n",
      " 1: 283 [D loss: 1.184, acc:  45] [G loss: 0.160]\n",
      " 1: 284 [D loss: 1.319, acc:  44] [G loss: 0.171]\n",
      " 1: 285 [D loss: 1.194, acc:  45] [G loss: 0.175]\n",
      " 1: 286 [D loss: 1.355, acc:  44] [G loss: 0.163]\n",
      " 1: 287 [D loss: 1.370, acc:  41] [G loss: 0.180]\n",
      " 1: 288 [D loss: 1.109, acc:  48] [G loss: 0.172]\n",
      " 1: 289 [D loss: 1.385, acc:  44] [G loss: 0.163]\n",
      " 1: 290 [D loss: 1.170, acc:  45] [G loss: 0.172]\n",
      " 1: 291 [D loss: 1.386, acc:  44] [G loss: 0.173]\n",
      " 1: 292 [D loss: 1.219, acc:  47] [G loss: 0.167]\n",
      " 1: 293 [D loss: 1.254, acc:  42] [G loss: 0.170]\n",
      " 1: 294 [D loss: 1.241, acc:  45] [G loss: 0.169]\n",
      " 1: 295 [D loss: 1.122, acc:  47] [G loss: 0.167]\n",
      " 1: 296 [D loss: 1.300, acc:  44] [G loss: 0.170]\n",
      " 1: 297 [D loss: 1.184, acc:  45] [G loss: 0.173]\n",
      " 1: 298 [D loss: 1.210, acc:  47] [G loss: 0.171]\n",
      " 1: 299 [D loss: 1.110, acc:  47] [G loss: 0.185]\n",
      " 1: 300 [D loss: 1.154, acc:  48] [G loss: 0.173]\n",
      " 1: 301 [D loss: 1.201, acc:  47] [G loss: 0.173]\n",
      " 1: 302 [D loss: 1.227, acc:  44] [G loss: 0.180]\n",
      " 1: 303 [D loss: 1.144, acc:  44] [G loss: 0.172]\n",
      " 1: 304 [D loss: 1.291, acc:  42] [G loss: 0.177]\n",
      " 1: 305 [D loss: 1.230, acc:  44] [G loss: 0.175]\n",
      " 1: 306 [D loss: 1.092, acc:  47] [G loss: 0.176]\n",
      " 1: 307 [D loss: 1.108, acc:  45] [G loss: 0.179]\n",
      " 1: 308 [D loss: 1.133, acc:  45] [G loss: 0.174]\n",
      " 1: 309 [D loss: 1.064, acc:  48] [G loss: 0.170]\n",
      " 1: 310 [D loss: 1.221, acc:  44] [G loss: 0.176]\n",
      " 1: 311 [D loss: 1.154, acc:  45] [G loss: 0.179]\n",
      " 1: 312 [D loss: 1.140, acc:  47] [G loss: 0.178]\n",
      " 1: 313 [D loss: 1.105, acc:  47] [G loss: 0.174]\n",
      " 1: 314 [D loss: 1.188, acc:  44] [G loss: 0.178]\n",
      " 1: 315 [D loss: 1.107, acc:  45] [G loss: 0.173]\n",
      " 1: 316 [D loss: 1.273, acc:  44] [G loss: 0.174]\n",
      " 1: 317 [D loss: 1.258, acc:  45] [G loss: 0.174]\n",
      " 1: 318 [D loss: 1.205, acc:  47] [G loss: 0.181]\n",
      " 1: 319 [D loss: 1.479, acc:  42] [G loss: 0.175]\n",
      " 1: 320 [D loss: 1.148, acc:  45] [G loss: 0.176]\n",
      " 1: 321 [D loss: 1.165, acc:  45] [G loss: 0.173]\n",
      " 1: 322 [D loss: 1.226, acc:  44] [G loss: 0.180]\n",
      " 1: 323 [D loss: 1.246, acc:  44] [G loss: 0.178]\n",
      " 1: 324 [D loss: 1.091, acc:  45] [G loss: 0.176]\n",
      " 1: 325 [D loss: 1.300, acc:  44] [G loss: 0.178]\n",
      " 1: 326 [D loss: 1.170, acc:  45] [G loss: 0.172]\n",
      " 1: 327 [D loss: 1.326, acc:  39] [G loss: 0.175]\n",
      " 1: 328 [D loss: 1.154, acc:  44] [G loss: 0.169]\n",
      " 1: 329 [D loss: 1.102, acc:  48] [G loss: 0.176]\n",
      " 1: 330 [D loss: 1.139, acc:  44] [G loss: 0.174]\n",
      " 1: 331 [D loss: 1.172, acc:  45] [G loss: 0.171]\n",
      " 1: 332 [D loss: 1.129, acc:  47] [G loss: 0.173]\n",
      " 1: 333 [D loss: 1.295, acc:  41] [G loss: 0.169]\n",
      " 1: 334 [D loss: 1.091, acc:  48] [G loss: 0.174]\n",
      " 1: 335 [D loss: 1.290, acc:  44] [G loss: 0.168]\n",
      " 1: 336 [D loss: 1.185, acc:  47] [G loss: 0.172]\n",
      " 1: 337 [D loss: 1.263, acc:  41] [G loss: 0.173]\n",
      " 1: 338 [D loss: 1.169, acc:  47] [G loss: 0.174]\n",
      " 1: 339 [D loss: 1.145, acc:  45] [G loss: 0.178]\n",
      " 1: 340 [D loss: 1.179, acc:  48] [G loss: 0.175]\n",
      " 1: 341 [D loss: 1.078, acc:  50] [G loss: 0.175]\n",
      " 1: 342 [D loss: 1.090, acc:  45] [G loss: 0.174]\n",
      " 1: 343 [D loss: 1.215, acc:  47] [G loss: 0.176]\n",
      " 1: 344 [D loss: 1.518, acc:  36] [G loss: 0.171]\n",
      " 1: 345 [D loss: 1.144, acc:  48] [G loss: 0.169]\n",
      " 1: 346 [D loss: 1.139, acc:  48] [G loss: 0.177]\n",
      " 1: 347 [D loss: 1.201, acc:  41] [G loss: 0.171]\n",
      " 1: 348 [D loss: 1.155, acc:  45] [G loss: 0.181]\n",
      " 1: 349 [D loss: 1.128, acc:  48] [G loss: 0.179]\n",
      " 1: 350 [D loss: 1.168, acc:  44] [G loss: 0.179]\n",
      " 1: 351 [D loss: 1.159, acc:  42] [G loss: 0.179]\n",
      " 1: 352 [D loss: 1.152, acc:  45] [G loss: 0.173]\n",
      " 1: 353 [D loss: 1.284, acc:  39] [G loss: 0.177]\n",
      " 1: 354 [D loss: 1.051, acc:  50] [G loss: 0.174]\n",
      " 1: 355 [D loss: 1.223, acc:  44] [G loss: 0.175]\n",
      " 1: 356 [D loss: 1.175, acc:  47] [G loss: 0.177]\n",
      " 1: 357 [D loss: 1.163, acc:  47] [G loss: 0.175]\n",
      " 1: 358 [D loss: 1.148, acc:  42] [G loss: 0.174]\n",
      " 1: 359 [D loss: 1.222, acc:  42] [G loss: 0.175]\n",
      " 1: 360 [D loss: 1.202, acc:  47] [G loss: 0.174]\n",
      " 1: 361 [D loss: 1.369, acc:  41] [G loss: 0.176]\n",
      " 1: 362 [D loss: 1.151, acc:  45] [G loss: 0.173]\n",
      " 1: 363 [D loss: 1.207, acc:  45] [G loss: 0.173]\n",
      " 1: 364 [D loss: 1.260, acc:  42] [G loss: 0.181]\n",
      " 1: 365 [D loss: 1.130, acc:  47] [G loss: 0.176]\n",
      " 1: 366 [D loss: 1.051, acc:  50] [G loss: 0.177]\n",
      " 1: 367 [D loss: 1.228, acc:  42] [G loss: 0.180]\n",
      " 1: 368 [D loss: 1.132, acc:  44] [G loss: 0.174]\n",
      " 1: 369 [D loss: 1.039, acc:  50] [G loss: 0.172]\n",
      " 1: 370 [D loss: 1.113, acc:  48] [G loss: 0.174]\n",
      " 1: 371 [D loss: 1.111, acc:  45] [G loss: 0.182]\n",
      " 1: 372 [D loss: 1.064, acc:  47] [G loss: 0.173]\n",
      " 1: 373 [D loss: 1.159, acc:  45] [G loss: 0.175]\n",
      " 1: 374 [D loss: 1.186, acc:  47] [G loss: 0.177]\n",
      " 1: 375 [D loss: 1.050, acc:  48] [G loss: 0.179]\n",
      " 1: 376 [D loss: 1.052, acc:  47] [G loss: 0.179]\n",
      " 1: 377 [D loss: 1.109, acc:  45] [G loss: 0.186]\n",
      " 1: 378 [D loss: 1.076, acc:  47] [G loss: 0.178]\n",
      " 1: 379 [D loss: 1.140, acc:  47] [G loss: 0.186]\n",
      " 1: 380 [D loss: 1.198, acc:  44] [G loss: 0.182]\n",
      " 1: 381 [D loss: 1.147, acc:  44] [G loss: 0.184]\n",
      " 1: 382 [D loss: 1.141, acc:  45] [G loss: 0.179]\n",
      " 1: 383 [D loss: 1.251, acc:  42] [G loss: 0.185]\n",
      " 1: 384 [D loss: 1.106, acc:  44] [G loss: 0.184]\n",
      " 1: 385 [D loss: 1.172, acc:  44] [G loss: 0.184]\n",
      " 1: 386 [D loss: 1.229, acc:  42] [G loss: 0.182]\n",
      " 1: 387 [D loss: 1.152, acc:  42] [G loss: 0.185]\n",
      " 1: 388 [D loss: 1.058, acc:  47] [G loss: 0.183]\n",
      " 1: 389 [D loss: 1.078, acc:  47] [G loss: 0.192]\n",
      " 1: 390 [D loss: 1.179, acc:  44] [G loss: 0.181]\n",
      " 1: 391 [D loss: 1.102, acc:  45] [G loss: 0.185]\n",
      " 1: 392 [D loss: 1.078, acc:  44] [G loss: 0.179]\n",
      " 1: 393 [D loss: 1.068, acc:  45] [G loss: 0.186]\n",
      " 1: 394 [D loss: 1.042, acc:  48] [G loss: 0.182]\n",
      " 1: 395 [D loss: 1.155, acc:  48] [G loss: 0.183]\n",
      " 1: 396 [D loss: 1.076, acc:  47] [G loss: 0.185]\n",
      " 1: 397 [D loss: 1.094, acc:  47] [G loss: 0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: 398 [D loss: 1.278, acc:  41] [G loss: 0.186]\n",
      " 1: 399 [D loss: 1.081, acc:  47] [G loss: 0.190]\n",
      " 1: 400 [D loss: 1.106, acc:  41] [G loss: 0.187]\n",
      " 1: 401 [D loss: 1.195, acc:  45] [G loss: 0.186]\n",
      " 1: 402 [D loss: 1.083, acc:  47] [G loss: 0.187]\n",
      " 1: 403 [D loss: 1.033, acc:  45] [G loss: 0.188]\n",
      " 1: 404 [D loss: 1.185, acc:  44] [G loss: 0.185]\n",
      " 1: 405 [D loss: 1.185, acc:  41] [G loss: 0.184]\n",
      " 1: 406 [D loss: 1.103, acc:  47] [G loss: 0.182]\n",
      " 1: 407 [D loss: 1.218, acc:  45] [G loss: 0.185]\n",
      " 1: 408 [D loss: 1.095, acc:  47] [G loss: 0.188]\n",
      " 1: 409 [D loss: 1.134, acc:  45] [G loss: 0.189]\n",
      " 1: 410 [D loss: 1.032, acc:  50] [G loss: 0.187]\n",
      " 1: 411 [D loss: 1.256, acc:  44] [G loss: 0.186]\n",
      " 1: 412 [D loss: 1.183, acc:  44] [G loss: 0.190]\n",
      " 1: 413 [D loss: 1.011, acc:  47] [G loss: 0.186]\n",
      " 1: 414 [D loss: 1.198, acc:  42] [G loss: 0.191]\n",
      " 1: 415 [D loss: 0.994, acc:  50] [G loss: 0.186]\n",
      " 1: 416 [D loss: 1.367, acc:  42] [G loss: 0.187]\n",
      " 1: 417 [D loss: 1.012, acc:  48] [G loss: 0.187]\n",
      " 1: 418 [D loss: 1.008, acc:  48] [G loss: 0.187]\n",
      " 1: 419 [D loss: 1.220, acc:  42] [G loss: 0.186]\n",
      " 1: 420 [D loss: 1.047, acc:  47] [G loss: 0.188]\n",
      " 1: 421 [D loss: 1.131, acc:  45] [G loss: 0.190]\n",
      " 1: 422 [D loss: 1.123, acc:  45] [G loss: 0.188]\n",
      " 1: 423 [D loss: 1.100, acc:  48] [G loss: 0.189]\n",
      " 2:   0 [D loss: 1.262, acc:  45] [G loss: 0.187]\n",
      " 2:   1 [D loss: 1.075, acc:  44] [G loss: 0.188]\n",
      " 2:   2 [D loss: 1.076, acc:  47] [G loss: 0.188]\n",
      " 2:   3 [D loss: 1.008, acc:  47] [G loss: 0.191]\n",
      " 2:   4 [D loss: 1.091, acc:  44] [G loss: 0.188]\n",
      " 2:   5 [D loss: 1.026, acc:  45] [G loss: 0.189]\n",
      " 2:   6 [D loss: 1.077, acc:  45] [G loss: 0.192]\n",
      " 2:   7 [D loss: 1.053, acc:  48] [G loss: 0.188]\n",
      " 2:   8 [D loss: 1.055, acc:  47] [G loss: 0.187]\n",
      " 2:   9 [D loss: 1.289, acc:  44] [G loss: 0.192]\n",
      " 2:  10 [D loss: 1.047, acc:  47] [G loss: 0.192]\n",
      " 2:  11 [D loss: 1.033, acc:  47] [G loss: 0.190]\n",
      " 2:  12 [D loss: 0.993, acc:  48] [G loss: 0.191]\n",
      " 2:  13 [D loss: 1.130, acc:  47] [G loss: 0.190]\n",
      " 2:  14 [D loss: 1.225, acc:  45] [G loss: 0.193]\n",
      " 2:  15 [D loss: 1.204, acc:  44] [G loss: 0.192]\n",
      " 2:  16 [D loss: 1.073, acc:  42] [G loss: 0.192]\n",
      " 2:  17 [D loss: 1.007, acc:  47] [G loss: 0.191]\n",
      " 2:  18 [D loss: 1.084, acc:  47] [G loss: 0.191]\n",
      " 2:  19 [D loss: 1.001, acc:  50] [G loss: 0.191]\n",
      " 2:  20 [D loss: 1.009, acc:  48] [G loss: 0.191]\n",
      " 2:  21 [D loss: 1.038, acc:  48] [G loss: 0.196]\n",
      " 2:  22 [D loss: 1.014, acc:  47] [G loss: 0.196]\n",
      " 2:  23 [D loss: 0.990, acc:  50] [G loss: 0.196]\n",
      " 2:  24 [D loss: 1.044, acc:  45] [G loss: 0.200]\n",
      " 2:  25 [D loss: 1.042, acc:  47] [G loss: 0.204]\n",
      " 2:  26 [D loss: 1.272, acc:  42] [G loss: 0.198]\n",
      " 2:  27 [D loss: 1.088, acc:  44] [G loss: 0.201]\n",
      " 2:  28 [D loss: 0.983, acc:  48] [G loss: 0.198]\n",
      " 2:  29 [D loss: 1.088, acc:  47] [G loss: 0.198]\n",
      " 2:  30 [D loss: 0.978, acc:  50] [G loss: 0.200]\n",
      " 2:  31 [D loss: 1.138, acc:  45] [G loss: 0.195]\n",
      " 2:  32 [D loss: 0.989, acc:  48] [G loss: 0.204]\n",
      " 2:  33 [D loss: 1.015, acc:  48] [G loss: 0.199]\n",
      " 2:  34 [D loss: 1.256, acc:  42] [G loss: 0.204]\n",
      " 2:  35 [D loss: 1.133, acc:  45] [G loss: 0.205]\n",
      " 2:  36 [D loss: 1.025, acc:  47] [G loss: 0.199]\n",
      " 2:  37 [D loss: 1.030, acc:  47] [G loss: 0.200]\n",
      " 2:  38 [D loss: 1.002, acc:  47] [G loss: 0.201]\n",
      " 2:  39 [D loss: 1.081, acc:  47] [G loss: 0.201]\n",
      " 2:  40 [D loss: 1.195, acc:  45] [G loss: 0.205]\n",
      " 2:  41 [D loss: 1.040, acc:  48] [G loss: 0.205]\n",
      " 2:  42 [D loss: 0.987, acc:  47] [G loss: 0.205]\n",
      " 2:  43 [D loss: 1.003, acc:  47] [G loss: 0.203]\n",
      " 2:  44 [D loss: 1.017, acc:  47] [G loss: 0.207]\n",
      " 2:  45 [D loss: 1.135, acc:  45] [G loss: 0.203]\n",
      " 2:  46 [D loss: 1.159, acc:  42] [G loss: 0.202]\n",
      " 2:  47 [D loss: 1.073, acc:  47] [G loss: 0.206]\n",
      " 2:  48 [D loss: 1.005, acc:  45] [G loss: 0.210]\n",
      " 2:  49 [D loss: 0.952, acc:  50] [G loss: 0.210]\n",
      " 2:  50 [D loss: 1.054, acc:  47] [G loss: 0.206]\n",
      " 2:  51 [D loss: 1.010, acc:  45] [G loss: 0.205]\n",
      " 2:  52 [D loss: 1.029, acc:  44] [G loss: 0.211]\n",
      " 2:  53 [D loss: 0.967, acc:  48] [G loss: 0.210]\n",
      " 2:  54 [D loss: 1.036, acc:  47] [G loss: 0.209]\n",
      " 2:  55 [D loss: 1.071, acc:  42] [G loss: 0.207]\n",
      " 2:  56 [D loss: 1.254, acc:  42] [G loss: 0.209]\n",
      " 2:  57 [D loss: 0.949, acc:  48] [G loss: 0.205]\n",
      " 2:  58 [D loss: 0.987, acc:  47] [G loss: 0.205]\n",
      " 2:  59 [D loss: 1.019, acc:  45] [G loss: 0.208]\n",
      " 2:  60 [D loss: 1.074, acc:  47] [G loss: 0.214]\n",
      " 2:  61 [D loss: 1.000, acc:  47] [G loss: 0.207]\n",
      " 2:  62 [D loss: 1.101, acc:  44] [G loss: 0.211]\n",
      " 2:  63 [D loss: 0.964, acc:  47] [G loss: 0.210]\n",
      " 2:  64 [D loss: 0.995, acc:  47] [G loss: 0.210]\n",
      " 2:  65 [D loss: 1.029, acc:  48] [G loss: 0.211]\n",
      " 2:  66 [D loss: 0.990, acc:  47] [G loss: 0.205]\n",
      " 2:  67 [D loss: 1.033, acc:  44] [G loss: 0.209]\n",
      " 2:  68 [D loss: 0.956, acc:  47] [G loss: 0.214]\n",
      " 2:  69 [D loss: 0.940, acc:  50] [G loss: 0.214]\n",
      " 2:  70 [D loss: 1.070, acc:  41] [G loss: 0.215]\n",
      " 2:  71 [D loss: 1.075, acc:  42] [G loss: 0.212]\n",
      " 2:  72 [D loss: 1.175, acc:  45] [G loss: 0.211]\n",
      " 2:  73 [D loss: 0.986, acc:  48] [G loss: 0.216]\n",
      " 2:  74 [D loss: 0.962, acc:  47] [G loss: 0.215]\n",
      " 2:  75 [D loss: 0.961, acc:  48] [G loss: 0.218]\n",
      " 2:  76 [D loss: 0.972, acc:  47] [G loss: 0.216]\n",
      " 2:  77 [D loss: 0.930, acc:  48] [G loss: 0.217]\n",
      " 2:  78 [D loss: 0.981, acc:  48] [G loss: 0.214]\n",
      " 2:  79 [D loss: 0.977, acc:  47] [G loss: 0.216]\n",
      " 2:  80 [D loss: 0.932, acc:  48] [G loss: 0.219]\n",
      " 2:  81 [D loss: 0.981, acc:  45] [G loss: 0.214]\n",
      " 2:  82 [D loss: 1.070, acc:  45] [G loss: 0.222]\n",
      " 2:  83 [D loss: 0.930, acc:  50] [G loss: 0.217]\n",
      " 2:  84 [D loss: 0.948, acc:  47] [G loss: 0.219]\n",
      " 2:  85 [D loss: 1.113, acc:  45] [G loss: 0.219]\n",
      " 2:  86 [D loss: 1.042, acc:  44] [G loss: 0.217]\n",
      " 2:  87 [D loss: 0.925, acc:  50] [G loss: 0.217]\n",
      " 2:  88 [D loss: 0.970, acc:  45] [G loss: 0.221]\n",
      " 2:  89 [D loss: 0.971, acc:  47] [G loss: 0.220]\n",
      " 2:  90 [D loss: 0.909, acc:  47] [G loss: 0.225]\n",
      " 2:  91 [D loss: 1.064, acc:  47] [G loss: 0.221]\n",
      " 2:  92 [D loss: 0.973, acc:  45] [G loss: 0.219]\n",
      " 2:  93 [D loss: 0.988, acc:  47] [G loss: 0.225]\n",
      " 2:  94 [D loss: 0.983, acc:  48] [G loss: 0.222]\n",
      " 2:  95 [D loss: 1.158, acc:  44] [G loss: 0.224]\n",
      " 2:  96 [D loss: 1.103, acc:  42] [G loss: 0.219]\n",
      " 2:  97 [D loss: 0.998, acc:  44] [G loss: 0.223]\n",
      " 2:  98 [D loss: 0.886, acc:  50] [G loss: 0.224]\n",
      " 2:  99 [D loss: 0.956, acc:  48] [G loss: 0.225]\n",
      " 2: 100 [D loss: 0.943, acc:  48] [G loss: 0.227]\n",
      " 2: 101 [D loss: 1.116, acc:  42] [G loss: 0.231]\n",
      " 2: 102 [D loss: 1.011, acc:  44] [G loss: 0.229]\n",
      " 2: 103 [D loss: 0.951, acc:  44] [G loss: 0.229]\n",
      " 2: 104 [D loss: 0.995, acc:  47] [G loss: 0.226]\n",
      " 2: 105 [D loss: 0.946, acc:  48] [G loss: 0.225]\n",
      " 2: 106 [D loss: 0.917, acc:  48] [G loss: 0.222]\n",
      " 2: 107 [D loss: 0.906, acc:  47] [G loss: 0.225]\n",
      " 2: 108 [D loss: 0.972, acc:  47] [G loss: 0.226]\n",
      " 2: 109 [D loss: 1.144, acc:  42] [G loss: 0.226]\n",
      " 2: 110 [D loss: 0.939, acc:  47] [G loss: 0.226]\n",
      " 2: 111 [D loss: 1.007, acc:  45] [G loss: 0.227]\n",
      " 2: 112 [D loss: 0.961, acc:  47] [G loss: 0.224]\n",
      " 2: 113 [D loss: 0.896, acc:  47] [G loss: 0.228]\n",
      " 2: 114 [D loss: 1.044, acc:  44] [G loss: 0.229]\n",
      " 2: 115 [D loss: 0.917, acc:  47] [G loss: 0.227]\n",
      " 2: 116 [D loss: 0.919, acc:  48] [G loss: 0.229]\n",
      " 2: 117 [D loss: 0.985, acc:  48] [G loss: 0.229]\n",
      " 2: 118 [D loss: 1.044, acc:  45] [G loss: 0.229]\n",
      " 2: 119 [D loss: 1.009, acc:  47] [G loss: 0.227]\n",
      " 2: 120 [D loss: 1.022, acc:  45] [G loss: 0.229]\n",
      " 2: 121 [D loss: 1.160, acc:  41] [G loss: 0.231]\n",
      " 2: 122 [D loss: 1.158, acc:  45] [G loss: 0.229]\n",
      " 2: 123 [D loss: 1.042, acc:  45] [G loss: 0.229]\n",
      " 2: 124 [D loss: 0.991, acc:  47] [G loss: 0.229]\n",
      " 2: 125 [D loss: 0.903, acc:  50] [G loss: 0.229]\n",
      " 2: 126 [D loss: 0.968, acc:  44] [G loss: 0.233]\n",
      " 2: 127 [D loss: 0.908, acc:  48] [G loss: 0.231]\n",
      " 2: 128 [D loss: 1.071, acc:  45] [G loss: 0.231]\n",
      " 2: 129 [D loss: 1.105, acc:  44] [G loss: 0.232]\n",
      " 2: 130 [D loss: 0.953, acc:  45] [G loss: 0.231]\n",
      " 2: 131 [D loss: 0.981, acc:  47] [G loss: 0.234]\n",
      " 2: 132 [D loss: 1.002, acc:  44] [G loss: 0.230]\n",
      " 2: 133 [D loss: 0.953, acc:  47] [G loss: 0.230]\n",
      " 2: 134 [D loss: 1.058, acc:  42] [G loss: 0.232]\n",
      " 2: 135 [D loss: 0.923, acc:  47] [G loss: 0.233]\n",
      " 2: 136 [D loss: 0.974, acc:  47] [G loss: 0.233]\n",
      " 2: 137 [D loss: 0.895, acc:  50] [G loss: 0.233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2: 138 [D loss: 1.045, acc:  39] [G loss: 0.235]\n",
      " 2: 139 [D loss: 0.928, acc:  48] [G loss: 0.232]\n",
      " 2: 140 [D loss: 0.911, acc:  48] [G loss: 0.235]\n",
      " 2: 141 [D loss: 0.872, acc:  50] [G loss: 0.236]\n",
      " 2: 142 [D loss: 0.903, acc:  48] [G loss: 0.232]\n",
      " 2: 143 [D loss: 1.032, acc:  44] [G loss: 0.235]\n",
      " 2: 144 [D loss: 1.045, acc:  42] [G loss: 0.235]\n",
      " 2: 145 [D loss: 0.899, acc:  48] [G loss: 0.235]\n",
      " 2: 146 [D loss: 1.029, acc:  44] [G loss: 0.239]\n",
      " 2: 147 [D loss: 0.881, acc:  50] [G loss: 0.238]\n",
      " 2: 148 [D loss: 0.865, acc:  48] [G loss: 0.237]\n",
      " 2: 149 [D loss: 0.923, acc:  47] [G loss: 0.238]\n",
      " 2: 150 [D loss: 0.999, acc:  45] [G loss: 0.240]\n",
      " 2: 151 [D loss: 1.013, acc:  45] [G loss: 0.240]\n",
      " 2: 152 [D loss: 0.872, acc:  47] [G loss: 0.237]\n",
      " 2: 153 [D loss: 0.866, acc:  50] [G loss: 0.240]\n",
      " 2: 154 [D loss: 0.880, acc:  48] [G loss: 0.241]\n",
      " 2: 155 [D loss: 0.964, acc:  42] [G loss: 0.244]\n",
      " 2: 156 [D loss: 0.859, acc:  50] [G loss: 0.243]\n",
      " 2: 157 [D loss: 0.917, acc:  47] [G loss: 0.242]\n",
      " 2: 158 [D loss: 0.998, acc:  48] [G loss: 0.243]\n",
      " 2: 159 [D loss: 0.887, acc:  48] [G loss: 0.244]\n",
      " 2: 160 [D loss: 0.935, acc:  47] [G loss: 0.244]\n",
      " 2: 161 [D loss: 0.869, acc:  48] [G loss: 0.242]\n",
      " 2: 162 [D loss: 0.899, acc:  48] [G loss: 0.247]\n",
      " 2: 163 [D loss: 0.935, acc:  47] [G loss: 0.247]\n",
      " 2: 164 [D loss: 1.087, acc:  42] [G loss: 0.244]\n",
      " 2: 165 [D loss: 0.906, acc:  44] [G loss: 0.243]\n",
      " 2: 166 [D loss: 0.947, acc:  47] [G loss: 0.244]\n",
      " 2: 167 [D loss: 0.968, acc:  47] [G loss: 0.242]\n",
      " 2: 168 [D loss: 0.884, acc:  47] [G loss: 0.246]\n",
      " 2: 169 [D loss: 0.913, acc:  47] [G loss: 0.245]\n",
      " 2: 170 [D loss: 0.861, acc:  50] [G loss: 0.245]\n",
      " 2: 171 [D loss: 0.899, acc:  48] [G loss: 0.244]\n",
      " 2: 172 [D loss: 0.879, acc:  45] [G loss: 0.246]\n",
      " 2: 173 [D loss: 0.866, acc:  50] [G loss: 0.247]\n",
      " 2: 174 [D loss: 0.938, acc:  47] [G loss: 0.245]\n",
      " 2: 175 [D loss: 1.023, acc:  45] [G loss: 0.248]\n",
      " 2: 176 [D loss: 0.927, acc:  48] [G loss: 0.250]\n",
      " 2: 177 [D loss: 0.850, acc:  50] [G loss: 0.249]\n",
      " 2: 178 [D loss: 0.911, acc:  47] [G loss: 0.248]\n",
      " 2: 179 [D loss: 0.860, acc:  50] [G loss: 0.252]\n",
      " 2: 180 [D loss: 0.931, acc:  45] [G loss: 0.249]\n",
      " 2: 181 [D loss: 1.139, acc:  41] [G loss: 0.254]\n",
      " 2: 182 [D loss: 0.962, acc:  47] [G loss: 0.247]\n",
      " 2: 183 [D loss: 0.865, acc:  47] [G loss: 0.248]\n",
      " 2: 184 [D loss: 0.911, acc:  47] [G loss: 0.249]\n",
      " 2: 185 [D loss: 0.844, acc:  50] [G loss: 0.252]\n",
      " 2: 186 [D loss: 0.867, acc:  50] [G loss: 0.252]\n",
      " 2: 187 [D loss: 0.932, acc:  45] [G loss: 0.253]\n",
      " 2: 188 [D loss: 1.001, acc:  45] [G loss: 0.252]\n",
      " 2: 189 [D loss: 0.861, acc:  48] [G loss: 0.251]\n",
      " 2: 190 [D loss: 0.896, acc:  47] [G loss: 0.256]\n",
      " 2: 191 [D loss: 0.894, acc:  47] [G loss: 0.256]\n",
      " 2: 192 [D loss: 0.936, acc:  45] [G loss: 0.253]\n",
      " 2: 193 [D loss: 0.916, acc:  48] [G loss: 0.254]\n",
      " 2: 194 [D loss: 0.876, acc:  47] [G loss: 0.252]\n",
      " 2: 195 [D loss: 0.875, acc:  47] [G loss: 0.252]\n",
      " 2: 196 [D loss: 1.043, acc:  42] [G loss: 0.255]\n",
      " 2: 197 [D loss: 0.925, acc:  42] [G loss: 0.253]\n",
      " 2: 198 [D loss: 0.881, acc:  47] [G loss: 0.251]\n",
      " 2: 199 [D loss: 0.815, acc:  50] [G loss: 0.252]\n",
      " 2: 200 [D loss: 0.875, acc:  47] [G loss: 0.251]\n",
      " 2: 201 [D loss: 0.934, acc:  47] [G loss: 0.257]\n",
      " 2: 202 [D loss: 0.885, acc:  47] [G loss: 0.255]\n",
      " 2: 203 [D loss: 0.916, acc:  47] [G loss: 0.257]\n",
      " 2: 204 [D loss: 0.861, acc:  48] [G loss: 0.260]\n",
      " 2: 205 [D loss: 0.967, acc:  47] [G loss: 0.256]\n",
      " 2: 206 [D loss: 0.899, acc:  45] [G loss: 0.253]\n",
      " 2: 207 [D loss: 0.826, acc:  48] [G loss: 0.255]\n",
      " 2: 208 [D loss: 0.917, acc:  48] [G loss: 0.255]\n",
      " 2: 209 [D loss: 0.931, acc:  44] [G loss: 0.256]\n",
      " 2: 210 [D loss: 0.938, acc:  45] [G loss: 0.256]\n",
      " 2: 211 [D loss: 0.913, acc:  45] [G loss: 0.259]\n",
      " 2: 212 [D loss: 0.908, acc:  45] [G loss: 0.257]\n",
      " 2: 213 [D loss: 0.831, acc:  48] [G loss: 0.255]\n",
      " 2: 214 [D loss: 0.853, acc:  48] [G loss: 0.258]\n",
      " 2: 215 [D loss: 0.893, acc:  44] [G loss: 0.259]\n",
      " 2: 216 [D loss: 1.027, acc:  44] [G loss: 0.256]\n",
      " 2: 217 [D loss: 0.822, acc:  48] [G loss: 0.257]\n",
      " 2: 218 [D loss: 0.936, acc:  45] [G loss: 0.258]\n",
      " 2: 219 [D loss: 0.860, acc:  48] [G loss: 0.260]\n",
      " 2: 220 [D loss: 0.853, acc:  45] [G loss: 0.256]\n",
      " 2: 221 [D loss: 0.846, acc:  48] [G loss: 0.262]\n",
      " 2: 222 [D loss: 0.973, acc:  45] [G loss: 0.263]\n",
      " 2: 223 [D loss: 0.880, acc:  45] [G loss: 0.261]\n",
      " 2: 224 [D loss: 0.837, acc:  48] [G loss: 0.265]\n",
      " 2: 225 [D loss: 0.825, acc:  50] [G loss: 0.260]\n",
      " 2: 226 [D loss: 0.863, acc:  48] [G loss: 0.261]\n",
      " 2: 227 [D loss: 0.982, acc:  45] [G loss: 0.264]\n",
      " 2: 228 [D loss: 0.900, acc:  45] [G loss: 0.262]\n",
      " 2: 229 [D loss: 0.978, acc:  45] [G loss: 0.261]\n",
      " 2: 230 [D loss: 0.885, acc:  44] [G loss: 0.262]\n",
      " 2: 231 [D loss: 0.802, acc:  50] [G loss: 0.263]\n",
      " 2: 232 [D loss: 0.886, acc:  45] [G loss: 0.262]\n",
      " 2: 233 [D loss: 0.834, acc:  50] [G loss: 0.259]\n",
      " 2: 234 [D loss: 0.937, acc:  45] [G loss: 0.260]\n",
      " 2: 235 [D loss: 0.924, acc:  45] [G loss: 0.260]\n",
      " 2: 236 [D loss: 0.983, acc:  47] [G loss: 0.263]\n",
      " 2: 237 [D loss: 0.898, acc:  47] [G loss: 0.263]\n",
      " 2: 238 [D loss: 0.845, acc:  48] [G loss: 0.265]\n",
      " 2: 239 [D loss: 0.865, acc:  45] [G loss: 0.261]\n",
      " 2: 240 [D loss: 0.889, acc:  48] [G loss: 0.262]\n",
      " 2: 241 [D loss: 0.844, acc:  48] [G loss: 0.266]\n",
      " 2: 242 [D loss: 0.834, acc:  47] [G loss: 0.264]\n",
      " 2: 243 [D loss: 1.008, acc:  42] [G loss: 0.264]\n",
      " 2: 244 [D loss: 0.984, acc:  44] [G loss: 0.260]\n",
      " 2: 245 [D loss: 0.828, acc:  48] [G loss: 0.264]\n",
      " 2: 246 [D loss: 0.843, acc:  47] [G loss: 0.267]\n",
      " 2: 247 [D loss: 0.823, acc:  48] [G loss: 0.263]\n",
      " 2: 248 [D loss: 0.839, acc:  48] [G loss: 0.264]\n",
      " 2: 249 [D loss: 0.844, acc:  45] [G loss: 0.262]\n",
      " 2: 250 [D loss: 0.927, acc:  44] [G loss: 0.265]\n",
      " 2: 251 [D loss: 0.999, acc:  44] [G loss: 0.267]\n",
      " 2: 252 [D loss: 0.815, acc:  50] [G loss: 0.266]\n",
      " 2: 253 [D loss: 0.845, acc:  48] [G loss: 0.263]\n",
      " 2: 254 [D loss: 0.854, acc:  45] [G loss: 0.265]\n",
      " 2: 255 [D loss: 0.870, acc:  48] [G loss: 0.266]\n",
      " 2: 256 [D loss: 0.868, acc:  47] [G loss: 0.264]\n",
      " 2: 257 [D loss: 0.816, acc:  50] [G loss: 0.269]\n",
      " 2: 258 [D loss: 0.987, acc:  45] [G loss: 0.267]\n",
      " 2: 259 [D loss: 0.893, acc:  47] [G loss: 0.266]\n",
      " 2: 260 [D loss: 0.831, acc:  47] [G loss: 0.268]\n",
      " 2: 261 [D loss: 0.878, acc:  47] [G loss: 0.266]\n",
      " 2: 262 [D loss: 0.890, acc:  42] [G loss: 0.267]\n",
      " 2: 263 [D loss: 0.813, acc:  48] [G loss: 0.266]\n",
      " 2: 264 [D loss: 0.806, acc:  50] [G loss: 0.268]\n",
      " 2: 265 [D loss: 0.956, acc:  42] [G loss: 0.267]\n",
      " 2: 266 [D loss: 0.892, acc:  45] [G loss: 0.266]\n",
      " 2: 267 [D loss: 0.802, acc:  50] [G loss: 0.268]\n",
      " 2: 268 [D loss: 0.821, acc:  47] [G loss: 0.269]\n",
      " 2: 269 [D loss: 0.953, acc:  47] [G loss: 0.272]\n",
      " 2: 270 [D loss: 0.882, acc:  47] [G loss: 0.271]\n",
      " 2: 271 [D loss: 0.830, acc:  48] [G loss: 0.269]\n",
      " 2: 272 [D loss: 0.796, acc:  50] [G loss: 0.269]\n",
      " 2: 273 [D loss: 0.926, acc:  41] [G loss: 0.270]\n",
      " 2: 274 [D loss: 0.892, acc:  48] [G loss: 0.272]\n",
      " 2: 275 [D loss: 0.818, acc:  45] [G loss: 0.271]\n",
      " 2: 276 [D loss: 0.910, acc:  44] [G loss: 0.272]\n",
      " 2: 277 [D loss: 0.855, acc:  47] [G loss: 0.268]\n",
      " 2: 278 [D loss: 0.806, acc:  48] [G loss: 0.271]\n",
      " 2: 279 [D loss: 0.889, acc:  48] [G loss: 0.266]\n",
      " 2: 280 [D loss: 0.862, acc:  47] [G loss: 0.272]\n",
      " 2: 281 [D loss: 0.853, acc:  48] [G loss: 0.269]\n",
      " 2: 282 [D loss: 0.781, acc:  50] [G loss: 0.270]\n",
      " 2: 283 [D loss: 0.819, acc:  48] [G loss: 0.270]\n",
      " 2: 284 [D loss: 0.920, acc:  47] [G loss: 0.273]\n",
      " 2: 285 [D loss: 0.835, acc:  48] [G loss: 0.270]\n",
      " 2: 286 [D loss: 0.884, acc:  44] [G loss: 0.274]\n",
      " 2: 287 [D loss: 0.939, acc:  42] [G loss: 0.273]\n",
      " 2: 288 [D loss: 0.797, acc:  50] [G loss: 0.276]\n",
      " 2: 289 [D loss: 0.961, acc:  44] [G loss: 0.274]\n",
      " 2: 290 [D loss: 0.822, acc:  48] [G loss: 0.274]\n",
      " 2: 291 [D loss: 0.945, acc:  45] [G loss: 0.275]\n",
      " 2: 292 [D loss: 0.859, acc:  47] [G loss: 0.271]\n",
      " 2: 293 [D loss: 0.860, acc:  42] [G loss: 0.271]\n",
      " 2: 294 [D loss: 0.858, acc:  45] [G loss: 0.275]\n",
      " 2: 295 [D loss: 0.810, acc:  47] [G loss: 0.275]\n",
      " 2: 296 [D loss: 0.887, acc:  45] [G loss: 0.274]\n",
      " 2: 297 [D loss: 0.848, acc:  47] [G loss: 0.270]\n",
      " 2: 298 [D loss: 0.850, acc:  48] [G loss: 0.275]\n",
      " 2: 299 [D loss: 0.825, acc:  48] [G loss: 0.274]\n",
      " 2: 300 [D loss: 0.804, acc:  48] [G loss: 0.278]\n",
      " 2: 301 [D loss: 0.842, acc:  47] [G loss: 0.274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2: 302 [D loss: 0.831, acc:  48] [G loss: 0.277]\n",
      " 2: 303 [D loss: 0.817, acc:  48] [G loss: 0.278]\n",
      " 2: 304 [D loss: 0.882, acc:  45] [G loss: 0.275]\n",
      " 2: 305 [D loss: 0.848, acc:  45] [G loss: 0.278]\n",
      " 2: 306 [D loss: 0.793, acc:  48] [G loss: 0.275]\n",
      " 2: 307 [D loss: 0.793, acc:  50] [G loss: 0.276]\n",
      " 2: 308 [D loss: 0.808, acc:  48] [G loss: 0.281]\n",
      " 2: 309 [D loss: 0.802, acc:  50] [G loss: 0.280]\n",
      " 2: 310 [D loss: 0.830, acc:  45] [G loss: 0.279]\n",
      " 2: 311 [D loss: 0.833, acc:  47] [G loss: 0.282]\n",
      " 2: 312 [D loss: 0.832, acc:  47] [G loss: 0.276]\n",
      " 2: 313 [D loss: 0.793, acc:  50] [G loss: 0.280]\n",
      " 2: 314 [D loss: 0.848, acc:  47] [G loss: 0.283]\n",
      " 2: 315 [D loss: 0.794, acc:  50] [G loss: 0.278]\n",
      " 2: 316 [D loss: 0.869, acc:  48] [G loss: 0.282]\n",
      " 2: 317 [D loss: 0.877, acc:  48] [G loss: 0.279]\n",
      " 2: 318 [D loss: 0.838, acc:  47] [G loss: 0.279]\n",
      " 2: 319 [D loss: 1.011, acc:  44] [G loss: 0.277]\n",
      " 2: 320 [D loss: 0.846, acc:  47] [G loss: 0.278]\n",
      " 2: 321 [D loss: 0.827, acc:  47] [G loss: 0.280]\n",
      " 2: 322 [D loss: 0.871, acc:  45] [G loss: 0.279]\n",
      " 2: 323 [D loss: 0.847, acc:  47] [G loss: 0.279]\n",
      " 2: 324 [D loss: 0.807, acc:  48] [G loss: 0.278]\n",
      " 2: 325 [D loss: 0.905, acc:  45] [G loss: 0.277]\n",
      " 2: 326 [D loss: 0.818, acc:  47] [G loss: 0.277]\n",
      " 2: 327 [D loss: 0.913, acc:  47] [G loss: 0.278]\n",
      " 2: 328 [D loss: 0.825, acc:  45] [G loss: 0.275]\n",
      " 2: 329 [D loss: 0.796, acc:  48] [G loss: 0.275]\n",
      " 2: 330 [D loss: 0.809, acc:  50] [G loss: 0.279]\n",
      " 2: 331 [D loss: 0.835, acc:  47] [G loss: 0.277]\n",
      " 2: 332 [D loss: 0.813, acc:  50] [G loss: 0.278]\n",
      " 2: 333 [D loss: 0.901, acc:  45] [G loss: 0.276]\n",
      " 2: 334 [D loss: 0.800, acc:  48] [G loss: 0.277]\n",
      " 2: 335 [D loss: 0.897, acc:  47] [G loss: 0.277]\n",
      " 2: 336 [D loss: 0.824, acc:  48] [G loss: 0.279]\n",
      " 2: 337 [D loss: 0.876, acc:  47] [G loss: 0.277]\n",
      " 2: 338 [D loss: 0.817, acc:  48] [G loss: 0.277]\n",
      " 2: 339 [D loss: 0.820, acc:  48] [G loss: 0.280]\n",
      " 2: 340 [D loss: 0.836, acc:  48] [G loss: 0.279]\n",
      " 2: 341 [D loss: 0.810, acc:  50] [G loss: 0.278]\n",
      " 2: 342 [D loss: 0.799, acc:  48] [G loss: 0.281]\n",
      " 2: 343 [D loss: 0.868, acc:  47] [G loss: 0.282]\n",
      " 2: 344 [D loss: 0.980, acc:  41] [G loss: 0.282]\n",
      " 2: 345 [D loss: 0.810, acc:  48] [G loss: 0.276]\n",
      " 2: 346 [D loss: 0.836, acc:  48] [G loss: 0.281]\n",
      " 2: 347 [D loss: 0.851, acc:  47] [G loss: 0.277]\n",
      " 2: 348 [D loss: 0.822, acc:  48] [G loss: 0.279]\n",
      " 2: 349 [D loss: 0.824, acc:  48] [G loss: 0.280]\n",
      " 2: 350 [D loss: 0.820, acc:  47] [G loss: 0.283]\n",
      " 2: 351 [D loss: 0.811, acc:  47] [G loss: 0.283]\n",
      " 2: 352 [D loss: 0.820, acc:  47] [G loss: 0.279]\n",
      " 2: 353 [D loss: 0.893, acc:  44] [G loss: 0.277]\n",
      " 2: 354 [D loss: 0.755, acc:  50] [G loss: 0.278]\n",
      " 2: 355 [D loss: 0.870, acc:  45] [G loss: 0.280]\n",
      " 2: 356 [D loss: 0.841, acc:  47] [G loss: 0.278]\n",
      " 2: 357 [D loss: 0.823, acc:  48] [G loss: 0.280]\n",
      " 2: 358 [D loss: 0.820, acc:  48] [G loss: 0.280]\n",
      " 2: 359 [D loss: 0.863, acc:  45] [G loss: 0.280]\n",
      " 2: 360 [D loss: 0.867, acc:  47] [G loss: 0.280]\n",
      " 2: 361 [D loss: 0.943, acc:  44] [G loss: 0.279]\n",
      " 2: 362 [D loss: 0.836, acc:  47] [G loss: 0.279]\n",
      " 2: 363 [D loss: 0.854, acc:  47] [G loss: 0.278]\n",
      " 2: 364 [D loss: 0.887, acc:  44] [G loss: 0.280]\n",
      " 2: 365 [D loss: 0.813, acc:  47] [G loss: 0.284]\n",
      " 2: 366 [D loss: 0.776, acc:  50] [G loss: 0.283]\n",
      " 2: 367 [D loss: 0.853, acc:  47] [G loss: 0.281]\n",
      " 2: 368 [D loss: 0.843, acc:  44] [G loss: 0.281]\n",
      " 2: 369 [D loss: 0.773, acc:  50] [G loss: 0.280]\n",
      " 2: 370 [D loss: 0.803, acc:  48] [G loss: 0.283]\n",
      " 2: 371 [D loss: 0.799, acc:  48] [G loss: 0.281]\n",
      " 2: 372 [D loss: 0.790, acc:  50] [G loss: 0.279]\n",
      " 2: 373 [D loss: 0.834, acc:  47] [G loss: 0.287]\n",
      " 2: 374 [D loss: 0.871, acc:  48] [G loss: 0.285]\n",
      " 2: 375 [D loss: 0.772, acc:  50] [G loss: 0.281]\n",
      " 2: 376 [D loss: 0.799, acc:  50] [G loss: 0.283]\n",
      " 2: 377 [D loss: 0.797, acc:  47] [G loss: 0.284]\n",
      " 2: 378 [D loss: 0.766, acc:  50] [G loss: 0.285]\n",
      " 2: 379 [D loss: 0.817, acc:  48] [G loss: 0.287]\n",
      " 2: 380 [D loss: 0.876, acc:  45] [G loss: 0.285]\n",
      " 2: 381 [D loss: 0.814, acc:  45] [G loss: 0.283]\n",
      " 2: 382 [D loss: 0.818, acc:  48] [G loss: 0.284]\n",
      " 2: 383 [D loss: 0.895, acc:  45] [G loss: 0.287]\n",
      " 2: 384 [D loss: 0.807, acc:  48] [G loss: 0.283]\n",
      " 2: 385 [D loss: 0.852, acc:  45] [G loss: 0.283]\n",
      " 2: 386 [D loss: 0.874, acc:  45] [G loss: 0.286]\n",
      " 2: 387 [D loss: 0.839, acc:  45] [G loss: 0.287]\n",
      " 2: 388 [D loss: 0.775, acc:  48] [G loss: 0.283]\n",
      " 2: 389 [D loss: 0.792, acc:  48] [G loss: 0.285]\n",
      " 2: 390 [D loss: 0.864, acc:  45] [G loss: 0.284]\n",
      " 2: 391 [D loss: 0.798, acc:  48] [G loss: 0.284]\n",
      " 2: 392 [D loss: 0.786, acc:  50] [G loss: 0.285]\n",
      " 2: 393 [D loss: 0.798, acc:  48] [G loss: 0.282]\n",
      " 2: 394 [D loss: 0.781, acc:  50] [G loss: 0.283]\n",
      " 2: 395 [D loss: 0.839, acc:  48] [G loss: 0.286]\n",
      " 2: 396 [D loss: 0.797, acc:  48] [G loss: 0.287]\n",
      " 2: 397 [D loss: 0.806, acc:  48] [G loss: 0.284]\n",
      " 2: 398 [D loss: 0.891, acc:  44] [G loss: 0.286]\n",
      " 2: 399 [D loss: 0.799, acc:  50] [G loss: 0.288]\n",
      " 2: 400 [D loss: 0.787, acc:  48] [G loss: 0.287]\n",
      " 2: 401 [D loss: 0.870, acc:  47] [G loss: 0.284]\n",
      " 2: 402 [D loss: 0.781, acc:  48] [G loss: 0.290]\n",
      " 2: 403 [D loss: 0.772, acc:  50] [G loss: 0.287]\n",
      " 2: 404 [D loss: 0.836, acc:  47] [G loss: 0.285]\n",
      " 2: 405 [D loss: 0.871, acc:  47] [G loss: 0.285]\n",
      " 2: 406 [D loss: 0.828, acc:  48] [G loss: 0.286]\n",
      " 2: 407 [D loss: 0.916, acc:  45] [G loss: 0.286]\n",
      " 2: 408 [D loss: 0.800, acc:  47] [G loss: 0.288]\n",
      " 2: 409 [D loss: 0.832, acc:  48] [G loss: 0.286]\n",
      " 2: 410 [D loss: 0.766, acc:  50] [G loss: 0.289]\n",
      " 2: 411 [D loss: 0.903, acc:  44] [G loss: 0.287]\n",
      " 2: 412 [D loss: 0.851, acc:  45] [G loss: 0.286]\n",
      " 2: 413 [D loss: 0.774, acc:  50] [G loss: 0.286]\n",
      " 2: 414 [D loss: 0.873, acc:  45] [G loss: 0.287]\n",
      " 2: 415 [D loss: 0.771, acc:  50] [G loss: 0.288]\n",
      " 2: 416 [D loss: 0.977, acc:  42] [G loss: 0.286]\n",
      " 2: 417 [D loss: 0.768, acc:  50] [G loss: 0.288]\n",
      " 2: 418 [D loss: 0.773, acc:  50] [G loss: 0.286]\n",
      " 2: 419 [D loss: 0.881, acc:  47] [G loss: 0.286]\n",
      " 2: 420 [D loss: 0.798, acc:  50] [G loss: 0.287]\n",
      " 2: 421 [D loss: 0.826, acc:  47] [G loss: 0.285]\n",
      " 2: 422 [D loss: 0.810, acc:  48] [G loss: 0.287]\n",
      " 2: 423 [D loss: 0.805, acc:  48] [G loss: 0.289]\n",
      " 3:   0 [D loss: 0.913, acc:  45] [G loss: 0.289]\n",
      " 3:   1 [D loss: 0.804, acc:  48] [G loss: 0.288]\n",
      " 3:   2 [D loss: 0.798, acc:  47] [G loss: 0.291]\n",
      " 3:   3 [D loss: 0.775, acc:  48] [G loss: 0.288]\n",
      " 3:   4 [D loss: 0.820, acc:  47] [G loss: 0.288]\n",
      " 3:   5 [D loss: 0.774, acc:  50] [G loss: 0.291]\n",
      " 3:   6 [D loss: 0.819, acc:  48] [G loss: 0.289]\n",
      " 3:   7 [D loss: 0.791, acc:  48] [G loss: 0.289]\n",
      " 3:   8 [D loss: 0.810, acc:  47] [G loss: 0.288]\n",
      " 3:   9 [D loss: 0.907, acc:  44] [G loss: 0.290]\n",
      " 3:  10 [D loss: 0.782, acc:  50] [G loss: 0.287]\n",
      " 3:  11 [D loss: 0.778, acc:  48] [G loss: 0.293]\n",
      " 3:  12 [D loss: 0.760, acc:  48] [G loss: 0.292]\n",
      " 3:  13 [D loss: 0.825, acc:  47] [G loss: 0.290]\n",
      " 3:  14 [D loss: 0.875, acc:  47] [G loss: 0.286]\n",
      " 3:  15 [D loss: 0.858, acc:  47] [G loss: 0.290]\n",
      " 3:  16 [D loss: 0.809, acc:  48] [G loss: 0.288]\n",
      " 3:  17 [D loss: 0.767, acc:  48] [G loss: 0.288]\n",
      " 3:  18 [D loss: 0.812, acc:  48] [G loss: 0.291]\n",
      " 3:  19 [D loss: 0.772, acc:  50] [G loss: 0.289]\n",
      " 3:  20 [D loss: 0.776, acc:  48] [G loss: 0.291]\n",
      " 3:  21 [D loss: 0.798, acc:  48] [G loss: 0.290]\n",
      " 3:  22 [D loss: 0.762, acc:  48] [G loss: 0.296]\n",
      " 3:  23 [D loss: 0.768, acc:  50] [G loss: 0.293]\n",
      " 3:  24 [D loss: 0.790, acc:  48] [G loss: 0.295]\n",
      " 3:  25 [D loss: 0.786, acc:  48] [G loss: 0.294]\n",
      " 3:  26 [D loss: 0.924, acc:  45] [G loss: 0.295]\n",
      " 3:  27 [D loss: 0.805, acc:  44] [G loss: 0.292]\n",
      " 3:  28 [D loss: 0.776, acc:  50] [G loss: 0.294]\n",
      " 3:  29 [D loss: 0.813, acc:  48] [G loss: 0.292]\n",
      " 3:  30 [D loss: 0.762, acc:  50] [G loss: 0.295]\n",
      " 3:  31 [D loss: 0.845, acc:  45] [G loss: 0.294]\n",
      " 3:  32 [D loss: 0.764, acc:  50] [G loss: 0.293]\n",
      " 3:  33 [D loss: 0.776, acc:  48] [G loss: 0.296]\n",
      " 3:  34 [D loss: 0.906, acc:  44] [G loss: 0.294]\n",
      " 3:  35 [D loss: 0.842, acc:  45] [G loss: 0.294]\n",
      " 3:  36 [D loss: 0.796, acc:  47] [G loss: 0.295]\n",
      " 3:  37 [D loss: 0.783, acc:  48] [G loss: 0.293]\n",
      " 3:  38 [D loss: 0.767, acc:  47] [G loss: 0.297]\n",
      " 3:  39 [D loss: 0.818, acc:  47] [G loss: 0.295]\n",
      " 3:  40 [D loss: 0.869, acc:  45] [G loss: 0.292]\n",
      " 3:  41 [D loss: 0.781, acc:  48] [G loss: 0.295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3:  42 [D loss: 0.773, acc:  47] [G loss: 0.294]\n",
      " 3:  43 [D loss: 0.772, acc:  48] [G loss: 0.297]\n",
      " 3:  44 [D loss: 0.782, acc:  47] [G loss: 0.296]\n",
      " 3:  45 [D loss: 0.832, acc:  47] [G loss: 0.297]\n",
      " 3:  46 [D loss: 0.864, acc:  42] [G loss: 0.298]\n",
      " 3:  47 [D loss: 0.821, acc:  48] [G loss: 0.296]\n",
      " 3:  48 [D loss: 0.783, acc:  48] [G loss: 0.296]\n",
      " 3:  49 [D loss: 0.741, acc:  50] [G loss: 0.297]\n",
      " 3:  50 [D loss: 0.810, acc:  47] [G loss: 0.296]\n",
      " 3:  51 [D loss: 0.788, acc:  47] [G loss: 0.298]\n",
      " 3:  52 [D loss: 0.789, acc:  48] [G loss: 0.296]\n",
      " 3:  53 [D loss: 0.773, acc:  48] [G loss: 0.295]\n",
      " 3:  54 [D loss: 0.792, acc:  47] [G loss: 0.297]\n",
      " 3:  55 [D loss: 0.822, acc:  48] [G loss: 0.295]\n",
      " 3:  56 [D loss: 0.890, acc:  44] [G loss: 0.297]\n",
      " 3:  57 [D loss: 0.759, acc:  50] [G loss: 0.298]\n",
      " 3:  58 [D loss: 0.762, acc:  48] [G loss: 0.298]\n",
      " 3:  59 [D loss: 0.786, acc:  48] [G loss: 0.296]\n",
      " 3:  60 [D loss: 0.797, acc:  47] [G loss: 0.298]\n",
      " 3:  61 [D loss: 0.792, acc:  47] [G loss: 0.295]\n",
      " 3:  62 [D loss: 0.857, acc:  45] [G loss: 0.299]\n",
      " 3:  63 [D loss: 0.760, acc:  50] [G loss: 0.297]\n",
      " 3:  64 [D loss: 0.780, acc:  48] [G loss: 0.299]\n",
      " 3:  65 [D loss: 0.784, acc:  48] [G loss: 0.299]\n",
      " 3:  66 [D loss: 0.772, acc:  48] [G loss: 0.300]\n",
      " 3:  67 [D loss: 0.785, acc:  48] [G loss: 0.301]\n",
      " 3:  68 [D loss: 0.743, acc:  48] [G loss: 0.299]\n",
      " 3:  69 [D loss: 0.743, acc:  50] [G loss: 0.299]\n",
      " 3:  70 [D loss: 0.827, acc:  45] [G loss: 0.297]\n",
      " 3:  71 [D loss: 0.825, acc:  47] [G loss: 0.301]\n",
      " 3:  72 [D loss: 0.859, acc:  45] [G loss: 0.303]\n",
      " 3:  73 [D loss: 0.764, acc:  48] [G loss: 0.303]\n",
      " 3:  74 [D loss: 0.757, acc:  48] [G loss: 0.301]\n",
      " 3:  75 [D loss: 0.757, acc:  50] [G loss: 0.304]\n",
      " 3:  76 [D loss: 0.772, acc:  48] [G loss: 0.305]\n",
      " 3:  77 [D loss: 0.740, acc:  50] [G loss: 0.302]\n",
      " 3:  78 [D loss: 0.773, acc:  48] [G loss: 0.305]\n",
      " 3:  79 [D loss: 0.764, acc:  47] [G loss: 0.303]\n",
      " 3:  80 [D loss: 0.752, acc:  50] [G loss: 0.303]\n",
      " 3:  81 [D loss: 0.781, acc:  48] [G loss: 0.305]\n",
      " 3:  82 [D loss: 0.812, acc:  47] [G loss: 0.306]\n",
      " 3:  83 [D loss: 0.746, acc:  50] [G loss: 0.304]\n",
      " 3:  84 [D loss: 0.745, acc:  50] [G loss: 0.307]\n",
      " 3:  85 [D loss: 0.863, acc:  45] [G loss: 0.305]\n",
      " 3:  86 [D loss: 0.807, acc:  47] [G loss: 0.302]\n",
      " 3:  87 [D loss: 0.738, acc:  50] [G loss: 0.304]\n",
      " 3:  88 [D loss: 0.772, acc:  50] [G loss: 0.303]\n",
      " 3:  89 [D loss: 0.753, acc:  48] [G loss: 0.307]\n",
      " 3:  90 [D loss: 0.724, acc:  50] [G loss: 0.307]\n",
      " 3:  91 [D loss: 0.812, acc:  47] [G loss: 0.306]\n",
      " 3:  92 [D loss: 0.757, acc:  50] [G loss: 0.305]\n",
      " 3:  93 [D loss: 0.767, acc:  47] [G loss: 0.305]\n",
      " 3:  94 [D loss: 0.789, acc:  48] [G loss: 0.306]\n",
      " 3:  95 [D loss: 0.861, acc:  45] [G loss: 0.305]\n",
      " 3:  96 [D loss: 0.844, acc:  45] [G loss: 0.308]\n",
      " 3:  97 [D loss: 0.793, acc:  47] [G loss: 0.304]\n",
      " 3:  98 [D loss: 0.719, acc:  50] [G loss: 0.306]\n",
      " 3:  99 [D loss: 0.764, acc:  48] [G loss: 0.307]\n",
      " 3: 100 [D loss: 0.757, acc:  48] [G loss: 0.307]\n",
      " 3: 101 [D loss: 0.837, acc:  42] [G loss: 0.306]\n",
      " 3: 102 [D loss: 0.774, acc:  45] [G loss: 0.309]\n",
      " 3: 103 [D loss: 0.759, acc:  48] [G loss: 0.309]\n",
      " 3: 104 [D loss: 0.785, acc:  47] [G loss: 0.307]\n",
      " 3: 105 [D loss: 0.772, acc:  48] [G loss: 0.306]\n",
      " 3: 106 [D loss: 0.739, acc:  50] [G loss: 0.306]\n",
      " 3: 107 [D loss: 0.736, acc:  50] [G loss: 0.307]\n",
      " 3: 108 [D loss: 0.753, acc:  47] [G loss: 0.310]\n",
      " 3: 109 [D loss: 0.858, acc:  42] [G loss: 0.307]\n",
      " 3: 110 [D loss: 0.744, acc:  47] [G loss: 0.307]\n",
      " 3: 111 [D loss: 0.782, acc:  47] [G loss: 0.310]\n",
      " 3: 112 [D loss: 0.758, acc:  48] [G loss: 0.308]\n",
      " 3: 113 [D loss: 0.738, acc:  48] [G loss: 0.311]\n",
      " 3: 114 [D loss: 0.807, acc:  45] [G loss: 0.310]\n",
      " 3: 115 [D loss: 0.747, acc:  48] [G loss: 0.311]\n",
      " 3: 116 [D loss: 0.739, acc:  48] [G loss: 0.313]\n",
      " 3: 117 [D loss: 0.786, acc:  48] [G loss: 0.313]\n",
      " 3: 118 [D loss: 0.804, acc:  47] [G loss: 0.314]\n",
      " 3: 119 [D loss: 0.800, acc:  47] [G loss: 0.312]\n",
      " 3: 120 [D loss: 0.789, acc:  48] [G loss: 0.313]\n",
      " 3: 121 [D loss: 0.882, acc:  45] [G loss: 0.311]\n",
      " 3: 122 [D loss: 0.882, acc:  45] [G loss: 0.311]\n",
      " 3: 123 [D loss: 0.793, acc:  47] [G loss: 0.311]\n",
      " 3: 124 [D loss: 0.784, acc:  47] [G loss: 0.310]\n",
      " 3: 125 [D loss: 0.727, acc:  50] [G loss: 0.310]\n",
      " 3: 126 [D loss: 0.767, acc:  47] [G loss: 0.314]\n",
      " 3: 127 [D loss: 0.740, acc:  50] [G loss: 0.312]\n",
      " 3: 128 [D loss: 0.828, acc:  45] [G loss: 0.311]\n",
      " 3: 129 [D loss: 0.840, acc:  45] [G loss: 0.313]\n",
      " 3: 130 [D loss: 0.766, acc:  48] [G loss: 0.312]\n",
      " 3: 131 [D loss: 0.781, acc:  48] [G loss: 0.313]\n",
      " 3: 132 [D loss: 0.792, acc:  47] [G loss: 0.313]\n",
      " 3: 133 [D loss: 0.755, acc:  47] [G loss: 0.314]\n",
      " 3: 134 [D loss: 0.829, acc:  44] [G loss: 0.312]\n",
      " 3: 135 [D loss: 0.743, acc:  48] [G loss: 0.312]\n",
      " 3: 136 [D loss: 0.774, acc:  48] [G loss: 0.311]\n",
      " 3: 137 [D loss: 0.730, acc:  50] [G loss: 0.316]\n",
      " 3: 138 [D loss: 0.812, acc:  44] [G loss: 0.311]\n",
      " 3: 139 [D loss: 0.747, acc:  48] [G loss: 0.314]\n",
      " 3: 140 [D loss: 0.737, acc:  48] [G loss: 0.314]\n",
      " 3: 141 [D loss: 0.716, acc:  50] [G loss: 0.316]\n",
      " 3: 142 [D loss: 0.732, acc:  50] [G loss: 0.313]\n",
      " 3: 143 [D loss: 0.820, acc:  45] [G loss: 0.316]\n",
      " 3: 144 [D loss: 0.820, acc:  45] [G loss: 0.314]\n",
      " 3: 145 [D loss: 0.733, acc:  50] [G loss: 0.317]\n",
      " 3: 146 [D loss: 0.813, acc:  45] [G loss: 0.314]\n",
      " 3: 147 [D loss: 0.725, acc:  50] [G loss: 0.315]\n",
      " 3: 148 [D loss: 0.719, acc:  50] [G loss: 0.318]\n",
      " 3: 149 [D loss: 0.753, acc:  48] [G loss: 0.319]\n",
      " 3: 150 [D loss: 0.782, acc:  47] [G loss: 0.318]\n",
      " 3: 151 [D loss: 0.813, acc:  47] [G loss: 0.320]\n",
      " 3: 152 [D loss: 0.731, acc:  50] [G loss: 0.316]\n",
      " 3: 153 [D loss: 0.713, acc:  50] [G loss: 0.317]\n",
      " 3: 154 [D loss: 0.716, acc:  50] [G loss: 0.322]\n",
      " 3: 155 [D loss: 0.767, acc:  42] [G loss: 0.321]\n",
      " 3: 156 [D loss: 0.716, acc:  50] [G loss: 0.319]\n",
      " 3: 157 [D loss: 0.736, acc:  48] [G loss: 0.323]\n",
      " 3: 158 [D loss: 0.784, acc:  48] [G loss: 0.323]\n",
      " 3: 159 [D loss: 0.721, acc:  48] [G loss: 0.322]\n",
      " 3: 160 [D loss: 0.750, acc:  48] [G loss: 0.321]\n",
      " 3: 161 [D loss: 0.724, acc:  50] [G loss: 0.322]\n",
      " 3: 162 [D loss: 0.743, acc:  48] [G loss: 0.321]\n",
      " 3: 163 [D loss: 0.760, acc:  47] [G loss: 0.322]\n",
      " 3: 164 [D loss: 0.834, acc:  45] [G loss: 0.323]\n",
      " 3: 165 [D loss: 0.739, acc:  50] [G loss: 0.320]\n",
      " 3: 166 [D loss: 0.765, acc:  48] [G loss: 0.320]\n",
      " 3: 167 [D loss: 0.778, acc:  48] [G loss: 0.320]\n",
      " 3: 168 [D loss: 0.725, acc:  48] [G loss: 0.322]\n",
      " 3: 169 [D loss: 0.739, acc:  48] [G loss: 0.323]\n",
      " 3: 170 [D loss: 0.715, acc:  50] [G loss: 0.322]\n",
      " 3: 171 [D loss: 0.741, acc:  48] [G loss: 0.323]\n",
      " 3: 172 [D loss: 0.725, acc:  48] [G loss: 0.324]\n",
      " 3: 173 [D loss: 0.707, acc:  50] [G loss: 0.325]\n",
      " 3: 174 [D loss: 0.768, acc:  47] [G loss: 0.324]\n",
      " 3: 175 [D loss: 0.806, acc:  45] [G loss: 0.324]\n",
      " 3: 176 [D loss: 0.753, acc:  48] [G loss: 0.325]\n",
      " 3: 177 [D loss: 0.706, acc:  50] [G loss: 0.324]\n",
      " 3: 178 [D loss: 0.736, acc:  50] [G loss: 0.326]\n",
      " 3: 179 [D loss: 0.702, acc:  50] [G loss: 0.326]\n",
      " 3: 180 [D loss: 0.757, acc:  47] [G loss: 0.326]\n",
      " 3: 181 [D loss: 0.892, acc:  44] [G loss: 0.327]\n",
      " 3: 182 [D loss: 0.772, acc:  47] [G loss: 0.323]\n",
      " 3: 183 [D loss: 0.722, acc:  48] [G loss: 0.323]\n",
      " 3: 184 [D loss: 0.752, acc:  47] [G loss: 0.323]\n",
      " 3: 185 [D loss: 0.700, acc:  50] [G loss: 0.325]\n",
      " 3: 186 [D loss: 0.718, acc:  50] [G loss: 0.325]\n",
      " 3: 187 [D loss: 0.752, acc:  47] [G loss: 0.326]\n",
      " 3: 188 [D loss: 0.794, acc:  45] [G loss: 0.327]\n",
      " 3: 189 [D loss: 0.715, acc:  50] [G loss: 0.327]\n",
      " 3: 190 [D loss: 0.726, acc:  47] [G loss: 0.328]\n",
      " 3: 191 [D loss: 0.725, acc:  48] [G loss: 0.327]\n",
      " 3: 192 [D loss: 0.767, acc:  45] [G loss: 0.326]\n",
      " 3: 193 [D loss: 0.743, acc:  48] [G loss: 0.327]\n",
      " 3: 194 [D loss: 0.730, acc:  47] [G loss: 0.327]\n",
      " 3: 195 [D loss: 0.715, acc:  50] [G loss: 0.329]\n",
      " 3: 196 [D loss: 0.839, acc:  45] [G loss: 0.327]\n",
      " 3: 197 [D loss: 0.755, acc:  47] [G loss: 0.327]\n",
      " 3: 198 [D loss: 0.714, acc:  48] [G loss: 0.326]\n",
      " 3: 199 [D loss: 0.685, acc:  50] [G loss: 0.327]\n",
      " 3: 200 [D loss: 0.729, acc:  50] [G loss: 0.328]\n",
      " 3: 201 [D loss: 0.746, acc:  47] [G loss: 0.328]\n",
      " 3: 202 [D loss: 0.729, acc:  47] [G loss: 0.329]\n",
      " 3: 203 [D loss: 0.745, acc:  48] [G loss: 0.326]\n",
      " 3: 204 [D loss: 0.707, acc:  48] [G loss: 0.328]\n",
      " 3: 205 [D loss: 0.791, acc:  47] [G loss: 0.329]\n",
      " 3: 206 [D loss: 0.739, acc:  47] [G loss: 0.330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3: 207 [D loss: 0.702, acc:  50] [G loss: 0.330]\n",
      " 3: 208 [D loss: 0.755, acc:  48] [G loss: 0.329]\n",
      " 3: 209 [D loss: 0.751, acc:  47] [G loss: 0.329]\n",
      " 3: 210 [D loss: 0.763, acc:  48] [G loss: 0.331]\n",
      " 3: 211 [D loss: 0.734, acc:  47] [G loss: 0.331]\n",
      " 3: 212 [D loss: 0.744, acc:  47] [G loss: 0.331]\n",
      " 3: 213 [D loss: 0.702, acc:  48] [G loss: 0.331]\n",
      " 3: 214 [D loss: 0.713, acc:  48] [G loss: 0.333]\n",
      " 3: 215 [D loss: 0.734, acc:  45] [G loss: 0.333]\n",
      " 3: 216 [D loss: 0.818, acc:  45] [G loss: 0.333]\n",
      " 3: 217 [D loss: 0.689, acc:  50] [G loss: 0.331]\n",
      " 3: 218 [D loss: 0.771, acc:  47] [G loss: 0.335]\n",
      " 3: 219 [D loss: 0.720, acc:  50] [G loss: 0.331]\n",
      " 3: 220 [D loss: 0.713, acc:  48] [G loss: 0.331]\n",
      " 3: 221 [D loss: 0.705, acc:  48] [G loss: 0.332]\n",
      " 3: 222 [D loss: 0.789, acc:  45] [G loss: 0.333]\n",
      " 3: 223 [D loss: 0.722, acc:  45] [G loss: 0.334]\n",
      " 3: 224 [D loss: 0.710, acc:  50] [G loss: 0.333]\n",
      " 3: 225 [D loss: 0.705, acc:  50] [G loss: 0.334]\n",
      " 3: 226 [D loss: 0.709, acc:  48] [G loss: 0.334]\n",
      " 3: 227 [D loss: 0.786, acc:  47] [G loss: 0.336]\n",
      " 3: 228 [D loss: 0.729, acc:  48] [G loss: 0.333]\n",
      " 3: 229 [D loss: 0.798, acc:  45] [G loss: 0.331]\n",
      " 3: 230 [D loss: 0.729, acc:  47] [G loss: 0.331]\n",
      " 3: 231 [D loss: 0.687, acc:  50] [G loss: 0.336]\n",
      " 3: 232 [D loss: 0.744, acc:  47] [G loss: 0.335]\n",
      " 3: 233 [D loss: 0.710, acc:  50] [G loss: 0.333]\n",
      " 3: 234 [D loss: 0.770, acc:  47] [G loss: 0.334]\n",
      " 3: 235 [D loss: 0.755, acc:  47] [G loss: 0.335]\n",
      " 3: 236 [D loss: 0.800, acc:  47] [G loss: 0.335]\n",
      " 3: 237 [D loss: 0.747, acc:  47] [G loss: 0.333]\n",
      " 3: 238 [D loss: 0.716, acc:  48] [G loss: 0.334]\n",
      " 3: 239 [D loss: 0.723, acc:  47] [G loss: 0.337]\n",
      " 3: 240 [D loss: 0.739, acc:  48] [G loss: 0.335]\n",
      " 3: 241 [D loss: 0.698, acc:  50] [G loss: 0.338]\n",
      " 3: 242 [D loss: 0.698, acc:  50] [G loss: 0.335]\n",
      " 3: 243 [D loss: 0.798, acc:  42] [G loss: 0.337]\n",
      " 3: 244 [D loss: 0.787, acc:  45] [G loss: 0.336]\n",
      " 3: 245 [D loss: 0.700, acc:  48] [G loss: 0.336]\n",
      " 3: 246 [D loss: 0.706, acc:  48] [G loss: 0.336]\n",
      " 3: 247 [D loss: 0.695, acc:  48] [G loss: 0.337]\n",
      " 3: 248 [D loss: 0.703, acc:  48] [G loss: 0.339]\n",
      " 3: 249 [D loss: 0.705, acc:  50] [G loss: 0.339]\n",
      " 3: 250 [D loss: 0.758, acc:  45] [G loss: 0.336]\n",
      " 3: 251 [D loss: 0.812, acc:  44] [G loss: 0.338]\n",
      " 3: 252 [D loss: 0.692, acc:  50] [G loss: 0.337]\n",
      " 3: 253 [D loss: 0.705, acc:  50] [G loss: 0.338]\n",
      " 3: 254 [D loss: 0.719, acc:  47] [G loss: 0.339]\n",
      " 3: 255 [D loss: 0.723, acc:  48] [G loss: 0.340]\n",
      " 3: 256 [D loss: 0.717, acc:  47] [G loss: 0.337]\n",
      " 3: 257 [D loss: 0.695, acc:  50] [G loss: 0.340]\n",
      " 3: 258 [D loss: 0.781, acc:  47] [G loss: 0.340]\n",
      " 3: 259 [D loss: 0.747, acc:  48] [G loss: 0.340]\n",
      " 3: 260 [D loss: 0.698, acc:  48] [G loss: 0.337]\n",
      " 3: 261 [D loss: 0.728, acc:  48] [G loss: 0.338]\n",
      " 3: 262 [D loss: 0.732, acc:  44] [G loss: 0.338]\n",
      " 3: 263 [D loss: 0.693, acc:  50] [G loss: 0.340]\n",
      " 3: 264 [D loss: 0.687, acc:  50] [G loss: 0.340]\n",
      " 3: 265 [D loss: 0.770, acc:  44] [G loss: 0.342]\n",
      " 3: 266 [D loss: 0.730, acc:  45] [G loss: 0.340]\n",
      " 3: 267 [D loss: 0.685, acc:  50] [G loss: 0.340]\n",
      " 3: 268 [D loss: 0.688, acc:  50] [G loss: 0.345]\n",
      " 3: 269 [D loss: 0.767, acc:  47] [G loss: 0.340]\n",
      " 3: 270 [D loss: 0.726, acc:  47] [G loss: 0.344]\n",
      " 3: 271 [D loss: 0.703, acc:  48] [G loss: 0.342]\n",
      " 3: 272 [D loss: 0.674, acc:  50] [G loss: 0.344]\n",
      " 3: 273 [D loss: 0.759, acc:  45] [G loss: 0.342]\n",
      " 3: 274 [D loss: 0.732, acc:  48] [G loss: 0.345]\n",
      " 3: 275 [D loss: 0.692, acc:  48] [G loss: 0.342]\n",
      " 3: 276 [D loss: 0.761, acc:  45] [G loss: 0.342]\n",
      " 3: 277 [D loss: 0.719, acc:  48] [G loss: 0.346]\n",
      " 3: 278 [D loss: 0.678, acc:  48] [G loss: 0.346]\n",
      " 3: 279 [D loss: 0.731, acc:  48] [G loss: 0.344]\n",
      " 3: 280 [D loss: 0.725, acc:  47] [G loss: 0.346]\n",
      " 3: 281 [D loss: 0.707, acc:  48] [G loss: 0.348]\n",
      " 3: 282 [D loss: 0.665, acc:  50] [G loss: 0.346]\n",
      " 3: 283 [D loss: 0.695, acc:  48] [G loss: 0.348]\n",
      " 3: 284 [D loss: 0.757, acc:  47] [G loss: 0.347]\n",
      " 3: 285 [D loss: 0.691, acc:  48] [G loss: 0.347]\n",
      " 3: 286 [D loss: 0.725, acc:  47] [G loss: 0.349]\n",
      " 3: 287 [D loss: 0.785, acc:  47] [G loss: 0.349]\n",
      " 3: 288 [D loss: 0.672, acc:  50] [G loss: 0.349]\n",
      " 3: 289 [D loss: 0.779, acc:  44] [G loss: 0.345]\n",
      " 3: 290 [D loss: 0.686, acc:  48] [G loss: 0.349]\n",
      " 3: 291 [D loss: 0.773, acc:  45] [G loss: 0.350]\n",
      " 3: 292 [D loss: 0.725, acc:  47] [G loss: 0.346]\n",
      " 3: 293 [D loss: 0.718, acc:  48] [G loss: 0.347]\n",
      " 3: 294 [D loss: 0.711, acc:  45] [G loss: 0.350]\n",
      " 3: 295 [D loss: 0.680, acc:  48] [G loss: 0.350]\n",
      " 3: 296 [D loss: 0.730, acc:  45] [G loss: 0.351]\n",
      " 3: 297 [D loss: 0.713, acc:  48] [G loss: 0.350]\n",
      " 3: 298 [D loss: 0.712, acc:  48] [G loss: 0.350]\n",
      " 3: 299 [D loss: 0.691, acc:  48] [G loss: 0.349]\n",
      " 3: 300 [D loss: 0.684, acc:  48] [G loss: 0.351]\n",
      " 3: 301 [D loss: 0.705, acc:  47] [G loss: 0.350]\n",
      " 3: 302 [D loss: 0.702, acc:  48] [G loss: 0.351]\n",
      " 3: 303 [D loss: 0.694, acc:  50] [G loss: 0.352]\n",
      " 3: 304 [D loss: 0.733, acc:  47] [G loss: 0.351]\n",
      " 3: 305 [D loss: 0.705, acc:  47] [G loss: 0.352]\n",
      " 3: 306 [D loss: 0.673, acc:  50] [G loss: 0.353]\n",
      " 3: 307 [D loss: 0.666, acc:  50] [G loss: 0.354]\n",
      " 3: 308 [D loss: 0.685, acc:  50] [G loss: 0.355]\n",
      " 3: 309 [D loss: 0.667, acc:  50] [G loss: 0.356]\n",
      " 3: 310 [D loss: 0.700, acc:  48] [G loss: 0.355]\n",
      " 3: 311 [D loss: 0.693, acc:  48] [G loss: 0.355]\n",
      " 3: 312 [D loss: 0.695, acc:  48] [G loss: 0.354]\n",
      " 3: 313 [D loss: 0.673, acc:  50] [G loss: 0.357]\n",
      " 3: 314 [D loss: 0.709, acc:  47] [G loss: 0.354]\n",
      " 3: 315 [D loss: 0.677, acc:  50] [G loss: 0.358]\n",
      " 3: 316 [D loss: 0.716, acc:  48] [G loss: 0.357]\n",
      " 3: 317 [D loss: 0.733, acc:  48] [G loss: 0.356]\n",
      " 3: 318 [D loss: 0.703, acc:  48] [G loss: 0.355]\n",
      " 3: 319 [D loss: 0.803, acc:  44] [G loss: 0.355]\n",
      " 3: 320 [D loss: 0.702, acc:  48] [G loss: 0.357]\n",
      " 3: 321 [D loss: 0.685, acc:  47] [G loss: 0.356]\n",
      " 3: 322 [D loss: 0.730, acc:  48] [G loss: 0.355]\n",
      " 3: 323 [D loss: 0.707, acc:  47] [G loss: 0.354]\n",
      " 3: 324 [D loss: 0.670, acc:  50] [G loss: 0.357]\n",
      " 3: 325 [D loss: 0.743, acc:  45] [G loss: 0.355]\n",
      " 3: 326 [D loss: 0.675, acc:  50] [G loss: 0.356]\n",
      " 3: 327 [D loss: 0.748, acc:  47] [G loss: 0.354]\n",
      " 3: 328 [D loss: 0.693, acc:  48] [G loss: 0.356]\n",
      " 3: 329 [D loss: 0.668, acc:  50] [G loss: 0.358]\n",
      " 3: 330 [D loss: 0.683, acc:  50] [G loss: 0.357]\n",
      " 3: 331 [D loss: 0.689, acc:  48] [G loss: 0.359]\n",
      " 3: 332 [D loss: 0.682, acc:  50] [G loss: 0.360]\n",
      " 3: 333 [D loss: 0.733, acc:  45] [G loss: 0.356]\n",
      " 3: 334 [D loss: 0.665, acc:  50] [G loss: 0.358]\n",
      " 3: 335 [D loss: 0.736, acc:  47] [G loss: 0.356]\n",
      " 3: 336 [D loss: 0.686, acc:  48] [G loss: 0.359]\n",
      " 3: 337 [D loss: 0.735, acc:  47] [G loss: 0.358]\n",
      " 3: 338 [D loss: 0.689, acc:  48] [G loss: 0.361]\n",
      " 3: 339 [D loss: 0.673, acc:  48] [G loss: 0.359]\n",
      " 3: 340 [D loss: 0.698, acc:  48] [G loss: 0.361]\n",
      " 3: 341 [D loss: 0.674, acc:  50] [G loss: 0.361]\n",
      " 3: 342 [D loss: 0.667, acc:  48] [G loss: 0.361]\n",
      " 3: 343 [D loss: 0.723, acc:  48] [G loss: 0.359]\n",
      " 3: 344 [D loss: 0.791, acc:  45] [G loss: 0.361]\n",
      " 3: 345 [D loss: 0.666, acc:  48] [G loss: 0.360]\n",
      " 3: 346 [D loss: 0.680, acc:  48] [G loss: 0.362]\n",
      " 3: 347 [D loss: 0.706, acc:  48] [G loss: 0.361]\n",
      " 3: 348 [D loss: 0.692, acc:  48] [G loss: 0.362]\n",
      " 3: 349 [D loss: 0.691, acc:  48] [G loss: 0.361]\n",
      " 3: 350 [D loss: 0.688, acc:  47] [G loss: 0.364]\n",
      " 3: 351 [D loss: 0.674, acc:  48] [G loss: 0.364]\n",
      " 3: 352 [D loss: 0.688, acc:  47] [G loss: 0.362]\n",
      " 3: 353 [D loss: 0.723, acc:  45] [G loss: 0.365]\n",
      " 3: 354 [D loss: 0.651, acc:  50] [G loss: 0.364]\n",
      " 3: 355 [D loss: 0.711, acc:  47] [G loss: 0.363]\n",
      " 3: 356 [D loss: 0.701, acc:  48] [G loss: 0.363]\n",
      " 3: 357 [D loss: 0.684, acc:  48] [G loss: 0.366]\n",
      " 3: 358 [D loss: 0.672, acc:  50] [G loss: 0.365]\n",
      " 3: 359 [D loss: 0.712, acc:  45] [G loss: 0.364]\n",
      " 3: 360 [D loss: 0.712, acc:  48] [G loss: 0.364]\n",
      " 3: 361 [D loss: 0.752, acc:  44] [G loss: 0.365]\n",
      " 3: 362 [D loss: 0.701, acc:  47] [G loss: 0.363]\n",
      " 3: 363 [D loss: 0.709, acc:  48] [G loss: 0.361]\n",
      " 3: 364 [D loss: 0.738, acc:  47] [G loss: 0.363]\n",
      " 3: 365 [D loss: 0.671, acc:  48] [G loss: 0.364]\n",
      " 3: 366 [D loss: 0.650, acc:  50] [G loss: 0.364]\n",
      " 3: 367 [D loss: 0.707, acc:  48] [G loss: 0.364]\n",
      " 3: 368 [D loss: 0.688, acc:  45] [G loss: 0.367]\n",
      " 3: 369 [D loss: 0.654, acc:  50] [G loss: 0.367]\n",
      " 3: 370 [D loss: 0.661, acc:  48] [G loss: 0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3: 371 [D loss: 0.671, acc:  50] [G loss: 0.366]\n",
      " 3: 372 [D loss: 0.662, acc:  50] [G loss: 0.368]\n",
      " 3: 373 [D loss: 0.690, acc:  48] [G loss: 0.368]\n",
      " 3: 374 [D loss: 0.712, acc:  48] [G loss: 0.368]\n",
      " 3: 375 [D loss: 0.645, acc:  50] [G loss: 0.369]\n",
      " 3: 376 [D loss: 0.666, acc:  50] [G loss: 0.370]\n",
      " 3: 377 [D loss: 0.672, acc:  50] [G loss: 0.368]\n",
      " 3: 378 [D loss: 0.639, acc:  50] [G loss: 0.373]\n",
      " 3: 379 [D loss: 0.677, acc:  48] [G loss: 0.371]\n",
      " 3: 380 [D loss: 0.728, acc:  48] [G loss: 0.372]\n",
      " 3: 381 [D loss: 0.684, acc:  48] [G loss: 0.371]\n",
      " 3: 382 [D loss: 0.690, acc:  48] [G loss: 0.371]\n",
      " 3: 383 [D loss: 0.732, acc:  45] [G loss: 0.374]\n",
      " 3: 384 [D loss: 0.679, acc:  48] [G loss: 0.372]\n",
      " 3: 385 [D loss: 0.694, acc:  48] [G loss: 0.371]\n",
      " 3: 386 [D loss: 0.714, acc:  45] [G loss: 0.371]\n",
      " 3: 387 [D loss: 0.701, acc:  48] [G loss: 0.372]\n",
      " 3: 388 [D loss: 0.655, acc:  50] [G loss: 0.375]\n",
      " 3: 389 [D loss: 0.656, acc:  50] [G loss: 0.373]\n",
      " 3: 390 [D loss: 0.715, acc:  47] [G loss: 0.372]\n",
      " 3: 391 [D loss: 0.663, acc:  48] [G loss: 0.371]\n",
      " 3: 392 [D loss: 0.663, acc:  50] [G loss: 0.371]\n",
      " 3: 393 [D loss: 0.658, acc:  50] [G loss: 0.372]\n",
      " 3: 394 [D loss: 0.657, acc:  50] [G loss: 0.374]\n",
      " 3: 395 [D loss: 0.691, acc:  48] [G loss: 0.373]\n",
      " 3: 396 [D loss: 0.656, acc:  50] [G loss: 0.372]\n",
      " 3: 397 [D loss: 0.657, acc:  48] [G loss: 0.374]\n",
      " 3: 398 [D loss: 0.729, acc:  45] [G loss: 0.375]\n",
      " 3: 399 [D loss: 0.665, acc:  50] [G loss: 0.373]\n",
      " 3: 400 [D loss: 0.662, acc:  50] [G loss: 0.374]\n",
      " 3: 401 [D loss: 0.721, acc:  47] [G loss: 0.374]\n",
      " 3: 402 [D loss: 0.667, acc:  48] [G loss: 0.374]\n",
      " 3: 403 [D loss: 0.638, acc:  50] [G loss: 0.375]\n",
      " 3: 404 [D loss: 0.689, acc:  48] [G loss: 0.373]\n",
      " 3: 405 [D loss: 0.718, acc:  47] [G loss: 0.375]\n",
      " 3: 406 [D loss: 0.696, acc:  48] [G loss: 0.375]\n",
      " 3: 407 [D loss: 0.739, acc:  47] [G loss: 0.375]\n",
      " 3: 408 [D loss: 0.668, acc:  48] [G loss: 0.374]\n",
      " 3: 409 [D loss: 0.686, acc:  48] [G loss: 0.375]\n",
      " 3: 410 [D loss: 0.649, acc:  50] [G loss: 0.375]\n",
      " 3: 411 [D loss: 0.726, acc:  44] [G loss: 0.376]\n",
      " 3: 412 [D loss: 0.702, acc:  47] [G loss: 0.376]\n",
      " 3: 413 [D loss: 0.649, acc:  50] [G loss: 0.378]\n",
      " 3: 414 [D loss: 0.714, acc:  45] [G loss: 0.375]\n",
      " 3: 415 [D loss: 0.641, acc:  50] [G loss: 0.375]\n",
      " 3: 416 [D loss: 0.793, acc:  42] [G loss: 0.374]\n",
      " 3: 417 [D loss: 0.647, acc:  50] [G loss: 0.376]\n",
      " 3: 418 [D loss: 0.640, acc:  50] [G loss: 0.377]\n",
      " 3: 419 [D loss: 0.718, acc:  47] [G loss: 0.375]\n",
      " 3: 420 [D loss: 0.668, acc:  50] [G loss: 0.374]\n",
      " 3: 421 [D loss: 0.687, acc:  47] [G loss: 0.374]\n",
      " 3: 422 [D loss: 0.673, acc:  48] [G loss: 0.376]\n",
      " 3: 423 [D loss: 0.660, acc:  48] [G loss: 0.377]\n",
      " 4:   0 [D loss: 0.752, acc:  45] [G loss: 0.375]\n",
      " 4:   1 [D loss: 0.668, acc:  50] [G loss: 0.376]\n",
      " 4:   2 [D loss: 0.673, acc:  47] [G loss: 0.374]\n",
      " 4:   3 [D loss: 0.649, acc:  50] [G loss: 0.375]\n",
      " 4:   4 [D loss: 0.686, acc:  48] [G loss: 0.376]\n",
      " 4:   5 [D loss: 0.651, acc:  50] [G loss: 0.376]\n",
      " 4:   6 [D loss: 0.686, acc:  48] [G loss: 0.376]\n",
      " 4:   7 [D loss: 0.659, acc:  48] [G loss: 0.377]\n",
      " 4:   8 [D loss: 0.670, acc:  48] [G loss: 0.379]\n",
      " 4:   9 [D loss: 0.739, acc:  44] [G loss: 0.379]\n",
      " 4:  10 [D loss: 0.652, acc:  50] [G loss: 0.379]\n",
      " 4:  11 [D loss: 0.654, acc:  50] [G loss: 0.380]\n",
      " 4:  12 [D loss: 0.630, acc:  50] [G loss: 0.379]\n",
      " 4:  13 [D loss: 0.690, acc:  48] [G loss: 0.380]\n",
      " 4:  14 [D loss: 0.710, acc:  47] [G loss: 0.377]\n",
      " 4:  15 [D loss: 0.707, acc:  47] [G loss: 0.379]\n",
      " 4:  16 [D loss: 0.684, acc:  48] [G loss: 0.377]\n",
      " 4:  17 [D loss: 0.638, acc:  50] [G loss: 0.382]\n",
      " 4:  18 [D loss: 0.673, acc:  48] [G loss: 0.383]\n",
      " 4:  19 [D loss: 0.645, acc:  50] [G loss: 0.383]\n",
      " 4:  20 [D loss: 0.656, acc:  48] [G loss: 0.381]\n",
      " 4:  21 [D loss: 0.658, acc:  48] [G loss: 0.385]\n",
      " 4:  22 [D loss: 0.635, acc:  48] [G loss: 0.386]\n",
      " 4:  23 [D loss: 0.653, acc:  50] [G loss: 0.381]\n",
      " 4:  24 [D loss: 0.656, acc:  50] [G loss: 0.382]\n",
      " 4:  25 [D loss: 0.657, acc:  48] [G loss: 0.386]\n",
      " 4:  26 [D loss: 0.739, acc:  45] [G loss: 0.384]\n",
      " 4:  27 [D loss: 0.675, acc:  47] [G loss: 0.382]\n",
      " 4:  28 [D loss: 0.650, acc:  50] [G loss: 0.383]\n",
      " 4:  29 [D loss: 0.671, acc:  48] [G loss: 0.384]\n",
      " 4:  30 [D loss: 0.642, acc:  50] [G loss: 0.385]\n",
      " 4:  31 [D loss: 0.700, acc:  45] [G loss: 0.384]\n",
      " 4:  32 [D loss: 0.651, acc:  50] [G loss: 0.383]\n",
      " 4:  33 [D loss: 0.647, acc:  50] [G loss: 0.385]\n",
      " 4:  34 [D loss: 0.736, acc:  44] [G loss: 0.384]\n",
      " 4:  35 [D loss: 0.702, acc:  45] [G loss: 0.381]\n",
      " 4:  36 [D loss: 0.675, acc:  47] [G loss: 0.383]\n",
      " 4:  37 [D loss: 0.661, acc:  50] [G loss: 0.381]\n",
      " 4:  38 [D loss: 0.646, acc:  48] [G loss: 0.384]\n",
      " 4:  39 [D loss: 0.671, acc:  47] [G loss: 0.385]\n",
      " 4:  40 [D loss: 0.713, acc:  45] [G loss: 0.386]\n",
      " 4:  41 [D loss: 0.649, acc:  48] [G loss: 0.384]\n",
      " 4:  42 [D loss: 0.640, acc:  48] [G loss: 0.384]\n",
      " 4:  43 [D loss: 0.642, acc:  48] [G loss: 0.387]\n",
      " 4:  44 [D loss: 0.652, acc:  48] [G loss: 0.386]\n",
      " 4:  45 [D loss: 0.687, acc:  47] [G loss: 0.386]\n",
      " 4:  46 [D loss: 0.712, acc:  44] [G loss: 0.383]\n",
      " 4:  47 [D loss: 0.687, acc:  48] [G loss: 0.385]\n",
      " 4:  48 [D loss: 0.659, acc:  48] [G loss: 0.386]\n",
      " 4:  49 [D loss: 0.615, acc:  50] [G loss: 0.385]\n",
      " 4:  50 [D loss: 0.665, acc:  48] [G loss: 0.386]\n",
      " 4:  51 [D loss: 0.655, acc:  48] [G loss: 0.388]\n",
      " 4:  52 [D loss: 0.657, acc:  48] [G loss: 0.389]\n",
      " 4:  53 [D loss: 0.660, acc:  48] [G loss: 0.385]\n",
      " 4:  54 [D loss: 0.657, acc:  48] [G loss: 0.389]\n",
      " 4:  55 [D loss: 0.690, acc:  48] [G loss: 0.387]\n",
      " 4:  56 [D loss: 0.738, acc:  44] [G loss: 0.386]\n",
      " 4:  57 [D loss: 0.636, acc:  50] [G loss: 0.386]\n",
      " 4:  58 [D loss: 0.645, acc:  48] [G loss: 0.388]\n",
      " 4:  59 [D loss: 0.657, acc:  48] [G loss: 0.388]\n",
      " 4:  60 [D loss: 0.664, acc:  47] [G loss: 0.386]\n",
      " 4:  61 [D loss: 0.659, acc:  47] [G loss: 0.389]\n",
      " 4:  62 [D loss: 0.712, acc:  47] [G loss: 0.388]\n",
      " 4:  63 [D loss: 0.640, acc:  50] [G loss: 0.388]\n",
      " 4:  64 [D loss: 0.656, acc:  48] [G loss: 0.388]\n",
      " 4:  65 [D loss: 0.666, acc:  48] [G loss: 0.389]\n",
      " 4:  66 [D loss: 0.651, acc:  48] [G loss: 0.389]\n",
      " 4:  67 [D loss: 0.659, acc:  48] [G loss: 0.389]\n",
      " 4:  68 [D loss: 0.627, acc:  48] [G loss: 0.388]\n",
      " 4:  69 [D loss: 0.624, acc:  50] [G loss: 0.390]\n",
      " 4:  70 [D loss: 0.695, acc:  45] [G loss: 0.391]\n",
      " 4:  71 [D loss: 0.681, acc:  47] [G loss: 0.393]\n",
      " 4:  72 [D loss: 0.706, acc:  45] [G loss: 0.392]\n",
      " 4:  73 [D loss: 0.643, acc:  48] [G loss: 0.390]\n",
      " 4:  74 [D loss: 0.631, acc:  48] [G loss: 0.393]\n",
      " 4:  75 [D loss: 0.641, acc:  50] [G loss: 0.393]\n",
      " 4:  76 [D loss: 0.648, acc:  50] [G loss: 0.392]\n",
      " 4:  77 [D loss: 0.622, acc:  50] [G loss: 0.394]\n",
      " 4:  78 [D loss: 0.651, acc:  48] [G loss: 0.393]\n",
      " 4:  79 [D loss: 0.649, acc:  48] [G loss: 0.391]\n",
      " 4:  80 [D loss: 0.639, acc:  50] [G loss: 0.393]\n",
      " 4:  81 [D loss: 0.655, acc:  48] [G loss: 0.394]\n",
      " 4:  82 [D loss: 0.691, acc:  47] [G loss: 0.391]\n",
      " 4:  83 [D loss: 0.631, acc:  50] [G loss: 0.393]\n",
      " 4:  84 [D loss: 0.635, acc:  50] [G loss: 0.392]\n",
      " 4:  85 [D loss: 0.725, acc:  45] [G loss: 0.393]\n",
      " 4:  86 [D loss: 0.684, acc:  47] [G loss: 0.392]\n",
      " 4:  87 [D loss: 0.624, acc:  50] [G loss: 0.394]\n",
      " 4:  88 [D loss: 0.654, acc:  50] [G loss: 0.391]\n",
      " 4:  89 [D loss: 0.632, acc:  50] [G loss: 0.398]\n",
      " 4:  90 [D loss: 0.614, acc:  50] [G loss: 0.393]\n",
      " 4:  91 [D loss: 0.687, acc:  47] [G loss: 0.393]\n",
      " 4:  92 [D loss: 0.639, acc:  50] [G loss: 0.395]\n",
      " 4:  93 [D loss: 0.643, acc:  47] [G loss: 0.399]\n",
      " 4:  94 [D loss: 0.674, acc:  48] [G loss: 0.394]\n",
      " 4:  95 [D loss: 0.711, acc:  45] [G loss: 0.393]\n",
      " 4:  96 [D loss: 0.697, acc:  45] [G loss: 0.395]\n",
      " 4:  97 [D loss: 0.669, acc:  47] [G loss: 0.393]\n",
      " 4:  98 [D loss: 0.609, acc:  50] [G loss: 0.395]\n",
      " 4:  99 [D loss: 0.649, acc:  48] [G loss: 0.397]\n",
      " 4: 100 [D loss: 0.634, acc:  50] [G loss: 0.393]\n",
      " 4: 101 [D loss: 0.688, acc:  42] [G loss: 0.394]\n",
      " 4: 102 [D loss: 0.661, acc:  45] [G loss: 0.394]\n",
      " 4: 103 [D loss: 0.651, acc:  50] [G loss: 0.396]\n",
      " 4: 104 [D loss: 0.653, acc:  47] [G loss: 0.396]\n",
      " 4: 105 [D loss: 0.651, acc:  48] [G loss: 0.395]\n",
      " 4: 106 [D loss: 0.626, acc:  50] [G loss: 0.395]\n",
      " 4: 107 [D loss: 0.623, acc:  50] [G loss: 0.395]\n",
      " 4: 108 [D loss: 0.644, acc:  47] [G loss: 0.396]\n",
      " 4: 109 [D loss: 0.723, acc:  42] [G loss: 0.395]\n",
      " 4: 110 [D loss: 0.635, acc:  48] [G loss: 0.397]\n",
      " 4: 111 [D loss: 0.653, acc:  47] [G loss: 0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4: 112 [D loss: 0.637, acc:  48] [G loss: 0.397]\n",
      " 4: 113 [D loss: 0.630, acc:  50] [G loss: 0.395]\n",
      " 4: 114 [D loss: 0.680, acc:  45] [G loss: 0.398]\n",
      " 4: 115 [D loss: 0.636, acc:  48] [G loss: 0.399]\n",
      " 4: 116 [D loss: 0.632, acc:  48] [G loss: 0.398]\n",
      " 4: 117 [D loss: 0.666, acc:  48] [G loss: 0.399]\n",
      " 4: 118 [D loss: 0.680, acc:  47] [G loss: 0.401]\n",
      " 4: 119 [D loss: 0.681, acc:  48] [G loss: 0.398]\n",
      " 4: 120 [D loss: 0.673, acc:  48] [G loss: 0.397]\n",
      " 4: 121 [D loss: 0.733, acc:  45] [G loss: 0.398]\n",
      " 4: 122 [D loss: 0.733, acc:  45] [G loss: 0.397]\n",
      " 4: 123 [D loss: 0.661, acc:  47] [G loss: 0.398]\n",
      " 4: 124 [D loss: 0.660, acc:  47] [G loss: 0.398]\n",
      " 4: 125 [D loss: 0.626, acc:  50] [G loss: 0.397]\n",
      " 4: 126 [D loss: 0.649, acc:  48] [G loss: 0.400]\n",
      " 4: 127 [D loss: 0.635, acc:  50] [G loss: 0.399]\n",
      " 4: 128 [D loss: 0.698, acc:  47] [G loss: 0.400]\n",
      " 4: 129 [D loss: 0.709, acc:  45] [G loss: 0.397]\n",
      " 4: 130 [D loss: 0.648, acc:  48] [G loss: 0.399]\n",
      " 4: 131 [D loss: 0.668, acc:  48] [G loss: 0.399]\n",
      " 4: 132 [D loss: 0.673, acc:  47] [G loss: 0.398]\n",
      " 4: 133 [D loss: 0.642, acc:  48] [G loss: 0.396]\n",
      " 4: 134 [D loss: 0.705, acc:  44] [G loss: 0.397]\n",
      " 4: 135 [D loss: 0.634, acc:  50] [G loss: 0.398]\n",
      " 4: 136 [D loss: 0.667, acc:  48] [G loss: 0.395]\n",
      " 4: 137 [D loss: 0.627, acc:  50] [G loss: 0.395]\n",
      " 4: 138 [D loss: 0.692, acc:  45] [G loss: 0.398]\n",
      " 4: 139 [D loss: 0.636, acc:  50] [G loss: 0.398]\n",
      " 4: 140 [D loss: 0.636, acc:  48] [G loss: 0.396]\n",
      " 4: 141 [D loss: 0.615, acc:  50] [G loss: 0.395]\n",
      " 4: 142 [D loss: 0.633, acc:  50] [G loss: 0.397]\n",
      " 4: 143 [D loss: 0.698, acc:  45] [G loss: 0.398]\n",
      " 4: 144 [D loss: 0.693, acc:  45] [G loss: 0.398]\n",
      " 4: 145 [D loss: 0.633, acc:  50] [G loss: 0.400]\n",
      " 4: 146 [D loss: 0.687, acc:  45] [G loss: 0.401]\n",
      " 4: 147 [D loss: 0.622, acc:  50] [G loss: 0.400]\n",
      " 4: 148 [D loss: 0.616, acc:  50] [G loss: 0.400]\n",
      " 4: 149 [D loss: 0.654, acc:  50] [G loss: 0.398]\n",
      " 4: 150 [D loss: 0.662, acc:  48] [G loss: 0.399]\n",
      " 4: 151 [D loss: 0.708, acc:  47] [G loss: 0.398]\n",
      " 4: 152 [D loss: 0.631, acc:  50] [G loss: 0.400]\n",
      " 4: 153 [D loss: 0.619, acc:  50] [G loss: 0.401]\n",
      " 4: 154 [D loss: 0.622, acc:  50] [G loss: 0.401]\n",
      " 4: 155 [D loss: 0.665, acc:  48] [G loss: 0.399]\n",
      " 4: 156 [D loss: 0.614, acc:  50] [G loss: 0.403]\n",
      " 4: 157 [D loss: 0.641, acc:  48] [G loss: 0.405]\n",
      " 4: 158 [D loss: 0.670, acc:  48] [G loss: 0.402]\n",
      " 4: 159 [D loss: 0.630, acc:  48] [G loss: 0.403]\n",
      " 4: 160 [D loss: 0.651, acc:  48] [G loss: 0.402]\n",
      " 4: 161 [D loss: 0.629, acc:  50] [G loss: 0.405]\n",
      " 4: 162 [D loss: 0.641, acc:  48] [G loss: 0.409]\n",
      " 4: 163 [D loss: 0.652, acc:  48] [G loss: 0.404]\n",
      " 4: 164 [D loss: 0.699, acc:  47] [G loss: 0.404]\n",
      " 4: 165 [D loss: 0.641, acc:  50] [G loss: 0.405]\n",
      " 4: 166 [D loss: 0.654, acc:  48] [G loss: 0.402]\n",
      " 4: 167 [D loss: 0.670, acc:  48] [G loss: 0.404]\n",
      " 4: 168 [D loss: 0.629, acc:  48] [G loss: 0.402]\n",
      " 4: 169 [D loss: 0.640, acc:  50] [G loss: 0.402]\n",
      " 4: 170 [D loss: 0.618, acc:  50] [G loss: 0.404]\n",
      " 4: 171 [D loss: 0.646, acc:  48] [G loss: 0.404]\n",
      " 4: 172 [D loss: 0.629, acc:  50] [G loss: 0.403]\n",
      " 4: 173 [D loss: 0.616, acc:  50] [G loss: 0.406]\n",
      " 4: 174 [D loss: 0.662, acc:  47] [G loss: 0.406]\n",
      " 4: 175 [D loss: 0.688, acc:  45] [G loss: 0.405]\n",
      " 4: 176 [D loss: 0.653, acc:  48] [G loss: 0.403]\n",
      " 4: 177 [D loss: 0.615, acc:  50] [G loss: 0.404]\n",
      " 4: 178 [D loss: 0.637, acc:  50] [G loss: 0.406]\n",
      " 4: 179 [D loss: 0.612, acc:  50] [G loss: 0.405]\n",
      " 4: 180 [D loss: 0.657, acc:  47] [G loss: 0.404]\n",
      " 4: 181 [D loss: 0.759, acc:  44] [G loss: 0.405]\n",
      " 4: 182 [D loss: 0.669, acc:  47] [G loss: 0.405]\n",
      " 4: 183 [D loss: 0.628, acc:  48] [G loss: 0.402]\n",
      " 4: 184 [D loss: 0.656, acc:  47] [G loss: 0.404]\n",
      " 4: 185 [D loss: 0.613, acc:  50] [G loss: 0.403]\n",
      " 4: 186 [D loss: 0.630, acc:  50] [G loss: 0.406]\n",
      " 4: 187 [D loss: 0.651, acc:  47] [G loss: 0.408]\n",
      " 4: 188 [D loss: 0.676, acc:  45] [G loss: 0.406]\n",
      " 4: 189 [D loss: 0.625, acc:  50] [G loss: 0.407]\n",
      " 4: 190 [D loss: 0.626, acc:  47] [G loss: 0.403]\n",
      " 4: 191 [D loss: 0.624, acc:  48] [G loss: 0.407]\n",
      " 4: 192 [D loss: 0.663, acc:  45] [G loss: 0.404]\n",
      " 4: 193 [D loss: 0.655, acc:  48] [G loss: 0.406]\n",
      " 4: 194 [D loss: 0.622, acc:  47] [G loss: 0.404]\n",
      " 4: 195 [D loss: 0.625, acc:  50] [G loss: 0.404]\n",
      " 4: 196 [D loss: 0.731, acc:  45] [G loss: 0.403]\n",
      " 4: 197 [D loss: 0.656, acc:  47] [G loss: 0.405]\n",
      " 4: 198 [D loss: 0.624, acc:  50] [G loss: 0.404]\n",
      " 4: 199 [D loss: 0.597, acc:  50] [G loss: 0.405]\n",
      " 4: 200 [D loss: 0.640, acc:  50] [G loss: 0.408]\n",
      " 4: 201 [D loss: 0.635, acc:  47] [G loss: 0.407]\n",
      " 4: 202 [D loss: 0.638, acc:  47] [G loss: 0.407]\n",
      " 4: 203 [D loss: 0.642, acc:  48] [G loss: 0.407]\n",
      " 4: 204 [D loss: 0.625, acc:  50] [G loss: 0.408]\n",
      " 4: 205 [D loss: 0.686, acc:  47] [G loss: 0.407]\n",
      " 4: 206 [D loss: 0.645, acc:  47] [G loss: 0.407]\n",
      " 4: 207 [D loss: 0.613, acc:  50] [G loss: 0.409]\n",
      " 4: 208 [D loss: 0.648, acc:  48] [G loss: 0.411]\n",
      " 4: 209 [D loss: 0.661, acc:  47] [G loss: 0.407]\n",
      " 4: 210 [D loss: 0.665, acc:  48] [G loss: 0.411]\n",
      " 4: 211 [D loss: 0.625, acc:  48] [G loss: 0.410]\n",
      " 4: 212 [D loss: 0.647, acc:  47] [G loss: 0.406]\n",
      " 4: 213 [D loss: 0.618, acc:  50] [G loss: 0.409]\n",
      " 4: 214 [D loss: 0.613, acc:  48] [G loss: 0.411]\n",
      " 4: 215 [D loss: 0.636, acc:  47] [G loss: 0.407]\n",
      " 4: 216 [D loss: 0.714, acc:  45] [G loss: 0.408]\n",
      " 4: 217 [D loss: 0.600, acc:  50] [G loss: 0.410]\n",
      " 4: 218 [D loss: 0.673, acc:  47] [G loss: 0.408]\n",
      " 4: 219 [D loss: 0.635, acc:  50] [G loss: 0.410]\n",
      " 4: 220 [D loss: 0.627, acc:  50] [G loss: 0.408]\n",
      " 4: 221 [D loss: 0.622, acc:  48] [G loss: 0.408]\n",
      " 4: 222 [D loss: 0.679, acc:  45] [G loss: 0.411]\n",
      " 4: 223 [D loss: 0.635, acc:  47] [G loss: 0.414]\n",
      " 4: 224 [D loss: 0.625, acc:  50] [G loss: 0.410]\n",
      " 4: 225 [D loss: 0.612, acc:  50] [G loss: 0.412]\n",
      " 4: 226 [D loss: 0.623, acc:  50] [G loss: 0.412]\n",
      " 4: 227 [D loss: 0.680, acc:  47] [G loss: 0.412]\n",
      " 4: 228 [D loss: 0.641, acc:  48] [G loss: 0.413]\n",
      " 4: 229 [D loss: 0.693, acc:  45] [G loss: 0.409]\n",
      " 4: 230 [D loss: 0.646, acc:  48] [G loss: 0.411]\n",
      " 4: 231 [D loss: 0.602, acc:  50] [G loss: 0.410]\n",
      " 4: 232 [D loss: 0.653, acc:  48] [G loss: 0.411]\n",
      " 4: 233 [D loss: 0.623, acc:  50] [G loss: 0.412]\n",
      " 4: 234 [D loss: 0.660, acc:  47] [G loss: 0.410]\n",
      " 4: 235 [D loss: 0.653, acc:  47] [G loss: 0.409]\n",
      " 4: 236 [D loss: 0.698, acc:  47] [G loss: 0.411]\n",
      " 4: 237 [D loss: 0.659, acc:  47] [G loss: 0.411]\n",
      " 4: 238 [D loss: 0.623, acc:  50] [G loss: 0.411]\n",
      " 4: 239 [D loss: 0.637, acc:  47] [G loss: 0.408]\n",
      " 4: 240 [D loss: 0.647, acc:  48] [G loss: 0.409]\n",
      " 4: 241 [D loss: 0.618, acc:  50] [G loss: 0.409]\n",
      " 4: 242 [D loss: 0.613, acc:  50] [G loss: 0.414]\n",
      " 4: 243 [D loss: 0.697, acc:  42] [G loss: 0.410]\n",
      " 4: 244 [D loss: 0.684, acc:  45] [G loss: 0.412]\n",
      " 4: 245 [D loss: 0.615, acc:  48] [G loss: 0.410]\n",
      " 4: 246 [D loss: 0.624, acc:  50] [G loss: 0.409]\n",
      " 4: 247 [D loss: 0.620, acc:  50] [G loss: 0.413]\n",
      " 4: 248 [D loss: 0.618, acc:  50] [G loss: 0.414]\n",
      " 4: 249 [D loss: 0.620, acc:  50] [G loss: 0.413]\n",
      " 4: 250 [D loss: 0.660, acc:  47] [G loss: 0.411]\n",
      " 4: 251 [D loss: 0.709, acc:  44] [G loss: 0.412]\n",
      " 4: 252 [D loss: 0.609, acc:  50] [G loss: 0.413]\n",
      " 4: 253 [D loss: 0.623, acc:  50] [G loss: 0.417]\n",
      " 4: 254 [D loss: 0.626, acc:  47] [G loss: 0.415]\n",
      " 4: 255 [D loss: 0.628, acc:  48] [G loss: 0.414]\n",
      " 4: 256 [D loss: 0.631, acc:  47] [G loss: 0.413]\n",
      " 4: 257 [D loss: 0.619, acc:  50] [G loss: 0.414]\n",
      " 4: 258 [D loss: 0.680, acc:  47] [G loss: 0.413]\n",
      " 4: 259 [D loss: 0.653, acc:  48] [G loss: 0.414]\n",
      " 4: 260 [D loss: 0.616, acc:  48] [G loss: 0.410]\n",
      " 4: 261 [D loss: 0.636, acc:  48] [G loss: 0.414]\n",
      " 4: 262 [D loss: 0.641, acc:  50] [G loss: 0.414]\n",
      " 4: 263 [D loss: 0.604, acc:  50] [G loss: 0.417]\n",
      " 4: 264 [D loss: 0.607, acc:  50] [G loss: 0.416]\n",
      " 4: 265 [D loss: 0.674, acc:  45] [G loss: 0.417]\n",
      " 4: 266 [D loss: 0.636, acc:  47] [G loss: 0.415]\n",
      " 4: 267 [D loss: 0.607, acc:  50] [G loss: 0.415]\n",
      " 4: 268 [D loss: 0.605, acc:  50] [G loss: 0.415]\n",
      " 4: 269 [D loss: 0.663, acc:  47] [G loss: 0.419]\n",
      " 4: 270 [D loss: 0.641, acc:  48] [G loss: 0.416]\n",
      " 4: 271 [D loss: 0.617, acc:  48] [G loss: 0.416]\n",
      " 4: 272 [D loss: 0.599, acc:  50] [G loss: 0.417]\n",
      " 4: 273 [D loss: 0.669, acc:  47] [G loss: 0.417]\n",
      " 4: 274 [D loss: 0.641, acc:  48] [G loss: 0.418]\n",
      " 4: 275 [D loss: 0.607, acc:  50] [G loss: 0.419]\n",
      " 4: 276 [D loss: 0.663, acc:  47] [G loss: 0.418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4: 277 [D loss: 0.629, acc:  48] [G loss: 0.422]\n",
      " 4: 278 [D loss: 0.598, acc:  48] [G loss: 0.417]\n",
      " 4: 279 [D loss: 0.640, acc:  48] [G loss: 0.419]\n",
      " 4: 280 [D loss: 0.643, acc:  48] [G loss: 0.419]\n",
      " 4: 281 [D loss: 0.622, acc:  48] [G loss: 0.419]\n",
      " 4: 282 [D loss: 0.591, acc:  50] [G loss: 0.420]\n",
      " 4: 283 [D loss: 0.625, acc:  48] [G loss: 0.420]\n",
      " 4: 284 [D loss: 0.658, acc:  47] [G loss: 0.422]\n",
      " 4: 285 [D loss: 0.613, acc:  48] [G loss: 0.420]\n",
      " 4: 286 [D loss: 0.638, acc:  47] [G loss: 0.423]\n",
      " 4: 287 [D loss: 0.686, acc:  47] [G loss: 0.424]\n",
      " 4: 288 [D loss: 0.599, acc:  50] [G loss: 0.422]\n",
      " 4: 289 [D loss: 0.676, acc:  45] [G loss: 0.419]\n",
      " 4: 290 [D loss: 0.607, acc:  48] [G loss: 0.423]\n",
      " 4: 291 [D loss: 0.680, acc:  45] [G loss: 0.420]\n",
      " 4: 292 [D loss: 0.637, acc:  47] [G loss: 0.420]\n",
      " 4: 293 [D loss: 0.633, acc:  48] [G loss: 0.422]\n",
      " 4: 294 [D loss: 0.626, acc:  45] [G loss: 0.421]\n",
      " 4: 295 [D loss: 0.606, acc:  48] [G loss: 0.424]\n",
      " 4: 296 [D loss: 0.638, acc:  47] [G loss: 0.423]\n",
      " 4: 297 [D loss: 0.624, acc:  48] [G loss: 0.422]\n",
      " 4: 298 [D loss: 0.635, acc:  48] [G loss: 0.426]\n",
      " 4: 299 [D loss: 0.615, acc:  48] [G loss: 0.423]\n",
      " 4: 300 [D loss: 0.607, acc:  48] [G loss: 0.423]\n",
      " 4: 301 [D loss: 0.624, acc:  47] [G loss: 0.425]\n",
      " 4: 302 [D loss: 0.619, acc:  48] [G loss: 0.423]\n",
      " 4: 303 [D loss: 0.614, acc:  50] [G loss: 0.422]\n",
      " 4: 304 [D loss: 0.647, acc:  47] [G loss: 0.424]\n",
      " 4: 305 [D loss: 0.619, acc:  48] [G loss: 0.420]\n",
      " 4: 306 [D loss: 0.594, acc:  50] [G loss: 0.424]\n",
      " 4: 307 [D loss: 0.595, acc:  50] [G loss: 0.425]\n",
      " 4: 308 [D loss: 0.610, acc:  50] [G loss: 0.426]\n",
      " 4: 309 [D loss: 0.599, acc:  50] [G loss: 0.427]\n",
      " 4: 310 [D loss: 0.621, acc:  48] [G loss: 0.424]\n",
      " 4: 311 [D loss: 0.620, acc:  48] [G loss: 0.428]\n",
      " 4: 312 [D loss: 0.614, acc:  48] [G loss: 0.426]\n",
      " 4: 313 [D loss: 0.603, acc:  50] [G loss: 0.428]\n",
      " 4: 314 [D loss: 0.629, acc:  47] [G loss: 0.426]\n",
      " 4: 315 [D loss: 0.607, acc:  50] [G loss: 0.427]\n",
      " 4: 316 [D loss: 0.636, acc:  48] [G loss: 0.426]\n",
      " 4: 317 [D loss: 0.646, acc:  48] [G loss: 0.426]\n",
      " 4: 318 [D loss: 0.620, acc:  48] [G loss: 0.430]\n",
      " 4: 319 [D loss: 0.703, acc:  44] [G loss: 0.426]\n",
      " 4: 320 [D loss: 0.626, acc:  48] [G loss: 0.426]\n",
      " 4: 321 [D loss: 0.606, acc:  48] [G loss: 0.427]\n",
      " 4: 322 [D loss: 0.649, acc:  48] [G loss: 0.424]\n",
      " 4: 323 [D loss: 0.626, acc:  47] [G loss: 0.427]\n",
      " 4: 324 [D loss: 0.596, acc:  50] [G loss: 0.427]\n",
      " 4: 325 [D loss: 0.656, acc:  48] [G loss: 0.427]\n",
      " 4: 326 [D loss: 0.598, acc:  50] [G loss: 0.427]\n",
      " 4: 327 [D loss: 0.666, acc:  47] [G loss: 0.425]\n",
      " 4: 328 [D loss: 0.619, acc:  48] [G loss: 0.425]\n",
      " 4: 329 [D loss: 0.598, acc:  50] [G loss: 0.429]\n",
      " 4: 330 [D loss: 0.613, acc:  50] [G loss: 0.426]\n",
      " 4: 331 [D loss: 0.610, acc:  48] [G loss: 0.426]\n",
      " 4: 332 [D loss: 0.614, acc:  50] [G loss: 0.427]\n",
      " 4: 333 [D loss: 0.648, acc:  47] [G loss: 0.428]\n",
      " 4: 334 [D loss: 0.594, acc:  50] [G loss: 0.429]\n",
      " 4: 335 [D loss: 0.644, acc:  47] [G loss: 0.429]\n",
      " 4: 336 [D loss: 0.608, acc:  48] [G loss: 0.425]\n",
      " 4: 337 [D loss: 0.651, acc:  47] [G loss: 0.428]\n",
      " 4: 338 [D loss: 0.620, acc:  48] [G loss: 0.428]\n",
      " 4: 339 [D loss: 0.601, acc:  50] [G loss: 0.427]\n",
      " 4: 340 [D loss: 0.621, acc:  48] [G loss: 0.434]\n",
      " 4: 341 [D loss: 0.607, acc:  50] [G loss: 0.429]\n",
      " 4: 342 [D loss: 0.596, acc:  50] [G loss: 0.429]\n",
      " 4: 343 [D loss: 0.648, acc:  48] [G loss: 0.429]\n",
      " 4: 344 [D loss: 0.689, acc:  45] [G loss: 0.428]\n",
      " 4: 345 [D loss: 0.601, acc:  50] [G loss: 0.428]\n",
      " 4: 346 [D loss: 0.610, acc:  48] [G loss: 0.429]\n",
      " 4: 347 [D loss: 0.634, acc:  48] [G loss: 0.431]\n",
      " 4: 348 [D loss: 0.616, acc:  48] [G loss: 0.430]\n",
      " 4: 349 [D loss: 0.619, acc:  48] [G loss: 0.429]\n",
      " 4: 350 [D loss: 0.614, acc:  47] [G loss: 0.431]\n",
      " 4: 351 [D loss: 0.598, acc:  50] [G loss: 0.431]\n",
      " 4: 352 [D loss: 0.612, acc:  48] [G loss: 0.432]\n",
      " 4: 353 [D loss: 0.638, acc:  47] [G loss: 0.432]\n",
      " 4: 354 [D loss: 0.586, acc:  50] [G loss: 0.430]\n",
      " 4: 355 [D loss: 0.632, acc:  47] [G loss: 0.430]\n",
      " 4: 356 [D loss: 0.628, acc:  48] [G loss: 0.432]\n",
      " 4: 357 [D loss: 0.620, acc:  48] [G loss: 0.431]\n",
      " 4: 358 [D loss: 0.603, acc:  50] [G loss: 0.432]\n",
      " 4: 359 [D loss: 0.647, acc:  45] [G loss: 0.429]\n",
      " 4: 360 [D loss: 0.638, acc:  48] [G loss: 0.432]\n",
      " 4: 361 [D loss: 0.663, acc:  44] [G loss: 0.431]\n",
      " 4: 362 [D loss: 0.629, acc:  47] [G loss: 0.430]\n",
      " 4: 363 [D loss: 0.628, acc:  48] [G loss: 0.432]\n",
      " 4: 364 [D loss: 0.657, acc:  47] [G loss: 0.431]\n",
      " 4: 365 [D loss: 0.602, acc:  48] [G loss: 0.430]\n",
      " 4: 366 [D loss: 0.584, acc:  50] [G loss: 0.432]\n",
      " 4: 367 [D loss: 0.633, acc:  48] [G loss: 0.430]\n",
      " 4: 368 [D loss: 0.615, acc:  48] [G loss: 0.433]\n",
      " 4: 369 [D loss: 0.594, acc:  50] [G loss: 0.430]\n",
      " 4: 370 [D loss: 0.591, acc:  48] [G loss: 0.432]\n",
      " 4: 371 [D loss: 0.601, acc:  50] [G loss: 0.435]\n",
      " 4: 372 [D loss: 0.602, acc:  50] [G loss: 0.432]\n",
      " 4: 373 [D loss: 0.613, acc:  48] [G loss: 0.436]\n",
      " 4: 374 [D loss: 0.632, acc:  48] [G loss: 0.434]\n",
      " 4: 375 [D loss: 0.588, acc:  50] [G loss: 0.434]\n",
      " 4: 376 [D loss: 0.596, acc:  50] [G loss: 0.435]\n",
      " 4: 377 [D loss: 0.604, acc:  50] [G loss: 0.436]\n",
      " 4: 378 [D loss: 0.580, acc:  50] [G loss: 0.440]\n",
      " 4: 379 [D loss: 0.608, acc:  48] [G loss: 0.438]\n",
      " 4: 380 [D loss: 0.656, acc:  48] [G loss: 0.438]\n",
      " 4: 381 [D loss: 0.610, acc:  48] [G loss: 0.439]\n",
      " 4: 382 [D loss: 0.618, acc:  48] [G loss: 0.438]\n",
      " 4: 383 [D loss: 0.647, acc:  45] [G loss: 0.437]\n",
      " 4: 384 [D loss: 0.615, acc:  50] [G loss: 0.437]\n",
      " 4: 385 [D loss: 0.621, acc:  50] [G loss: 0.436]\n",
      " 4: 386 [D loss: 0.641, acc:  45] [G loss: 0.434]\n",
      " 4: 387 [D loss: 0.626, acc:  48] [G loss: 0.436]\n",
      " 4: 388 [D loss: 0.587, acc:  50] [G loss: 0.438]\n",
      " 4: 389 [D loss: 0.593, acc:  50] [G loss: 0.437]\n",
      " 4: 390 [D loss: 0.642, acc:  48] [G loss: 0.436]\n",
      " 4: 391 [D loss: 0.599, acc:  48] [G loss: 0.434]\n",
      " 4: 392 [D loss: 0.600, acc:  50] [G loss: 0.437]\n",
      " 4: 393 [D loss: 0.597, acc:  50] [G loss: 0.438]\n",
      " 4: 394 [D loss: 0.592, acc:  50] [G loss: 0.437]\n",
      " 4: 395 [D loss: 0.613, acc:  48] [G loss: 0.438]\n",
      " 4: 396 [D loss: 0.591, acc:  50] [G loss: 0.441]\n",
      " 4: 397 [D loss: 0.593, acc:  48] [G loss: 0.439]\n",
      " 4: 398 [D loss: 0.646, acc:  47] [G loss: 0.441]\n",
      " 4: 399 [D loss: 0.601, acc:  50] [G loss: 0.441]\n",
      " 4: 400 [D loss: 0.597, acc:  50] [G loss: 0.442]\n",
      " 4: 401 [D loss: 0.641, acc:  47] [G loss: 0.439]\n",
      " 4: 402 [D loss: 0.596, acc:  48] [G loss: 0.441]\n",
      " 4: 403 [D loss: 0.576, acc:  50] [G loss: 0.443]\n",
      " 4: 404 [D loss: 0.618, acc:  50] [G loss: 0.440]\n",
      " 4: 405 [D loss: 0.640, acc:  48] [G loss: 0.439]\n",
      " 4: 406 [D loss: 0.632, acc:  48] [G loss: 0.438]\n",
      " 4: 407 [D loss: 0.652, acc:  47] [G loss: 0.441]\n",
      " 4: 408 [D loss: 0.598, acc:  50] [G loss: 0.441]\n",
      " 4: 409 [D loss: 0.617, acc:  48] [G loss: 0.441]\n",
      " 4: 410 [D loss: 0.592, acc:  50] [G loss: 0.441]\n",
      " 4: 411 [D loss: 0.643, acc:  44] [G loss: 0.439]\n",
      " 4: 412 [D loss: 0.628, acc:  47] [G loss: 0.439]\n",
      " 4: 413 [D loss: 0.588, acc:  50] [G loss: 0.440]\n",
      " 4: 414 [D loss: 0.647, acc:  45] [G loss: 0.441]\n",
      " 4: 415 [D loss: 0.583, acc:  50] [G loss: 0.441]\n",
      " 4: 416 [D loss: 0.696, acc:  42] [G loss: 0.439]\n",
      " 4: 417 [D loss: 0.584, acc:  50] [G loss: 0.440]\n",
      " 4: 418 [D loss: 0.582, acc:  50] [G loss: 0.441]\n",
      " 4: 419 [D loss: 0.637, acc:  47] [G loss: 0.439]\n",
      " 4: 420 [D loss: 0.607, acc:  50] [G loss: 0.441]\n",
      " 4: 421 [D loss: 0.617, acc:  47] [G loss: 0.439]\n",
      " 4: 422 [D loss: 0.602, acc:  50] [G loss: 0.439]\n",
      " 4: 423 [D loss: 0.597, acc:  48] [G loss: 0.441]\n"
     ]
    }
   ],
   "source": [
    "gan.train(windows.to_keras_sequence(32), num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_cols = (\"userAcceleration.x.real\", \"userAcceleration.y.real\", \"userAcceleration.z.real\")\n",
    "plotter = Plotter(VecData(windows[0][0], acc_cols, 10), dataset.FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.make_line_plot(\"Walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.make_2d_animations(\"Walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"subject\"] == df[\"subject\"].sample(n=1, random_state=1).iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"subject\"].sample(n=1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset.FREQUENCY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
